<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>machina.pixel.picture API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>machina.pixel.picture</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="machina.pixel.picture.add_centered_text"><code class="name flex">
<span>def <span class="ident">add_centered_text</span></span>(<span>picture: <a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a>,<br>text: str,<br>**kwargs) ‑> <a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_centered_text(picture: Picture, text: str, **kwargs) -&gt; Picture:

    # Function to wrap text
    def wrap_text(draw, text, font, max_width):
        lines = []
        words = text.split()
        current_line = []

        for word in words:
            # Join current line with the new word and calculate its width
            current_line.append(word)
            line_width, _ = draw.textbbox((0, 0), &#39; &#39;.join(current_line), font=font)[2:4]

            # If line exceeds max width, start a new line
            if line_width &gt; max_width:
                lines.append(&#39; &#39;.join(current_line[:-1]))  # Add previous line (without last word)
                current_line = [word]  # Start a new line with the current word

        lines.append(&#39; &#39;.join(current_line))  # Add the last line
        return lines



    text_color = kwargs.get(&#39;color&#39;, Color(0, 0, 0))
    font_size = kwargs.get(&#39;font_size&#39;, 40)


    picture = picture.copy()
    # Initialize ImageDraw object
    draw = ImageDraw.Draw(picture.image)


    # Get the path to the .ttf font in the parent directory (relative path)
    font_path = os.path.join(os.path.dirname(__file__), &#39;..&#39;, &#39;fonts&#39;, &#39;InterVariable.ttf&#39;)
    font = ImageFont.truetype(font_path, font_size)
    #font = ImageFont.load_default()

    # Wrap the text
    max_width = picture.width - 20  # Max width of the text block (with some padding)
    lines = wrap_text(draw, text, font, max_width)


    # Calculate the total height of the text block
    total_text_height = sum([draw.textbbox((0, 0), line, font=font)[3] for line in lines])

    # Calculate the starting position to center the text vertically
    y_start = (picture.height - total_text_height) // 2

    # Set the starting position for the text (horizontally centered)
    x_start = (picture.width - max_width) // 2

    # Draw each line of text
    y = y_start
    for line in lines:
        line_width = draw.textbbox((0, 0), line, font=font)[2]  # Calculate the width of the current line
        x_start = (picture.width - line_width) // 2  # Center the line horizontally
        draw.text((x_start, y), line, fill=text_color.rgb, font=font)
        y += draw.textbbox((0, 0), line, font=font)[3]  # Move to the next line&#39;s position


    return picture</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="machina.pixel.picture.blend_images"><code class="name flex">
<span>def <span class="ident">blend_images</span></span>(<span>image1: <a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a>,<br>image2: <a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a>,<br>**kwargs) ‑> <a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def blend_images(image1: Picture, image2: Picture, **kwargs) -&gt; Picture:
    &#34;&#34;&#34;
    This function blends two images of the same size and mode together using a specified alpha value.
    The blending is done using the `Image.blend` function from the PIL library, which combines the two
    images by mixing their pixel values based on the alpha parameter.

    Args:
        image1 (Picture): The first image (a `Picture` object) to blend.
        image2 (Picture): The second image (a `Picture` object) to blend.
        alpha (float, optional): A float value between 0 and 1 representing the blending factor.
                                 Default is 0.5, meaning an equal blend of both images.
                                 An alpha of 0.0 means the result will be entirely `image1`,
                                 and an alpha of 1.0 means the result will be entirely `image2`.

    Returns:
        Picture: A new `Picture` object containing the blended image.

    Raises:
        ValueError: If the two images do not have the same size or mode.

    Example:
        &gt;&gt;&gt; image1 = Picture(image1_data)
        &gt;&gt;&gt; image2 = Picture(image2_data)
        &gt;&gt;&gt; blended_image = blend_images(image1, image2, alpha=0.7)

    Notes:
        - Both images must have the same size and mode (e.g., both should be in RGB or RGBA).
        - The alpha value determines the influence of each image in the final blend. A value of 0.5 results in an equal blend of both images.
        - The result is a new image that blends the pixel values of the two input images based on the alpha value.
    &#34;&#34;&#34;

    if image1.size != image2.size:
        raise ValueError(&#34;Images must have the same size.&#34;)
    if image1.mode != image2.mode:
        raise ValueError(&#34;Images must have the same mode.&#34;)
    alpha = kwargs.get(&#39;alpha&#39;, 0.5)
    pil_image = Image.blend(image1.image, image2.image, alpha)
    return Picture.from_PIL_image(pil_image)</code></pre>
</details>
<div class="desc"><p>This function blends two images of the same size and mode together using a specified alpha value.
The blending is done using the <code>Image.blend</code> function from the PIL library, which combines the two
images by mixing their pixel values based on the alpha parameter.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image1</code></strong> :&ensp;<code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd>The first image (a <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> object) to blend.</dd>
<dt><strong><code>image2</code></strong> :&ensp;<code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd>The second image (a <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> object) to blend.</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>A float value between 0 and 1 representing the blending factor.
Default is 0.5, meaning an equal blend of both images.
An alpha of 0.0 means the result will be entirely <code>image1</code>,
and an alpha of 1.0 means the result will be entirely <code>image2</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd>A new <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> object containing the blended image.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the two images do not have the same size or mode.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; image1 = Picture(image1_data)
&gt;&gt;&gt; image2 = Picture(image2_data)
&gt;&gt;&gt; blended_image = blend_images(image1, image2, alpha=0.7)
</code></pre>
<h2 id="notes">Notes</h2>
<ul>
<li>Both images must have the same size and mode (e.g., both should be in RGB or RGBA).</li>
<li>The alpha value determines the influence of each image in the final blend. A value of 0.5 results in an equal blend of both images.</li>
<li>The result is a new image that blends the pixel values of the two input images based on the alpha value.</li>
</ul></div>
</dd>
<dt id="machina.pixel.picture.create_grid_of_pictures"><code class="name flex">
<span>def <span class="ident">create_grid_of_pictures</span></span>(<span>pictures: list[<a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a>],<br>**kwargs) ‑> <a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_grid_of_pictures(pictures: list[Picture], **kwargs) -&gt; Picture:
    &#34;&#34;&#34;
    Create a Grid of Pictures

    This function arranges a list of `Picture` objects into a grid layout. The grid is constructed based on
    the number of pictures provided, and each picture is resized to fit a uniform image size. The resulting
    grid of pictures is returned as a new `Picture` object.

    Args:
        pictures (list[Picture]): A list of `Picture` objects to be arranged into the grid.
        grid_size (tuple, optional): A tuple representing the number of columns and rows in the grid.
                                      If not provided, the grid will be created with an optimal square
                                      layout based on the number of pictures. Default is determined
                                      by the square root of the number of pictures.
        image_size (tuple, optional): A tuple representing the size (width, height) of each individual image
                                      in the grid. Default is (720, 720).

    Returns:
        Picture: A new `Picture` object containing the collage of images arranged in the grid.

    Raises:
        ValueError: If the input list of pictures is empty.

    Example:
        &gt;&gt;&gt; picture1 = Picture(image1_data)
        &gt;&gt;&gt; picture2 = Picture(image2_data)
        &gt;&gt;&gt; pictures = [picture1, picture2, picture3]
        &gt;&gt;&gt; grid_picture = create_grid_of_pictures(pictures, grid_size=(2, 2), image_size=(500, 500))

    Notes:
        - The images are resized to fit the specified `image_size`, and if necessary, the images are centered
          on a blank white background to maintain the aspect ratio.
        - If the number of pictures exceeds the grid size (cols * rows), extra images are ignored.
        - The resulting collage will have a white background for empty spaces.
    &#34;&#34;&#34;

    grid_size = kwargs.get(&#39;grid_size&#39;, (math.ceil(math.sqrt(len(pictures))), math.ceil(math.sqrt(len(pictures)))))
    image_size = kwargs.get(&#39;image_size&#39;, (720, 720))


    cols, rows = grid_size
    collage_width = cols * image_size[0]
    collage_height = rows * image_size[1]

    collage = Image.new(&#39;RGB&#39;, (collage_width, collage_height))

    for index, picture in enumerate(pictures):
        if index &gt;= cols * rows:
            break

        img = picture.image
        img.thumbnail(image_size)  # Maintain aspect ratio while resizing

        # Create a blank image with the target size and paste the resized image at the center
        temp_img = Image.new(&#39;RGB&#39;, image_size, (255, 255, 255))  # White background
        x_offset = (image_size[0] - img.size[0]) // 2
        y_offset = (image_size[1] - img.size[1]) // 2
        temp_img.paste(img, (x_offset, y_offset))

        x_offset = (index % cols) * image_size[0]
        y_offset = (index // cols) * image_size[1]

        collage.paste(temp_img, (x_offset, y_offset))

    return Picture.from_PIL_image(collage)</code></pre>
</details>
<div class="desc"><p>Create a Grid of Pictures</p>
<p>This function arranges a list of <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> objects into a grid layout. The grid is constructed based on
the number of pictures provided, and each picture is resized to fit a uniform image size. The resulting
grid of pictures is returned as a new <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> object.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>pictures</code></strong> :&ensp;<code>list[<a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a>]</code></dt>
<dd>A list of <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> objects to be arranged into the grid.</dd>
<dt><strong><code>grid_size</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>A tuple representing the number of columns and rows in the grid.
If not provided, the grid will be created with an optimal square
layout based on the number of pictures. Default is determined
by the square root of the number of pictures.</dd>
<dt><strong><code>image_size</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>A tuple representing the size (width, height) of each individual image
in the grid. Default is (720, 720).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd>A new <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> object containing the collage of images arranged in the grid.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the input list of pictures is empty.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; picture1 = Picture(image1_data)
&gt;&gt;&gt; picture2 = Picture(image2_data)
&gt;&gt;&gt; pictures = [picture1, picture2, picture3]
&gt;&gt;&gt; grid_picture = create_grid_of_pictures(pictures, grid_size=(2, 2), image_size=(500, 500))
</code></pre>
<h2 id="notes">Notes</h2>
<ul>
<li>The images are resized to fit the specified <code>image_size</code>, and if necessary, the images are centered
on a blank white background to maintain the aspect ratio.</li>
<li>If the number of pictures exceeds the grid size (cols * rows), extra images are ignored.</li>
<li>The resulting collage will have a white background for empty spaces.</li>
</ul></div>
</dd>
<dt id="machina.pixel.picture.get_blank_picture"><code class="name flex">
<span>def <span class="ident">get_blank_picture</span></span>(<span>width: int,<br>height: int,<br>color: <a title="machina.artist.color.Color" href="../artist/color.html#machina.artist.color.Color">Color</a>,<br>border_thickness=0,<br>border_color=Color: r: 0.0, g: 0.0, b: 0.0, a: 1.0) ‑> <a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_blank_picture(width: int, height: int, color: Color, border_thickness=0, border_color=Color(0, 0, 0)) -&gt; Picture:
    image = Image.new(&#34;RGB&#34;, (width, height), color.rgb)

    draw = ImageDraw.Draw(image)
    draw.rectangle([0, 0, width - 1, height - 1], outline=border_color.rgb, width=border_thickness)

    picture = Picture.from_PIL_image(image)
    return picture</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="machina.pixel.picture.screen_blend"><code class="name flex">
<span>def <span class="ident">screen_blend</span></span>(<span>pic1: <a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a>,<br>pic2: <a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a>) ‑> <a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def screen_blend(pic1: Picture, pic2: Picture) -&gt; Picture:
    &#34;&#34;&#34;
    Blends two PIL images using the &#39;Screen&#39; blend mode.
    Both images must be RGB or RGBA and will be resized to match the size of image1 if needed.
    &#34;&#34;&#34;
    # Convert images to same mode and size
    pic1.convert_to_rgb()
    pic2.convert_to_rgb()

    # Convert to numpy arrays
    arr1 = np.asarray(pic1.image).astype(&#39;float&#39;)
    arr2 = np.asarray(pic2.image).astype(&#39;float&#39;)

    # Apply screen blending formula
    blended = 255 - ((255 - arr1) * (255 - arr2) / 255)

    # Clip and convert back to uint8
    blended = np.clip(blended, 0, 255).astype(&#39;uint8&#39;)

    return Picture.from_PIL_image(Image.fromarray(blended))</code></pre>
</details>
<div class="desc"><p>Blends two PIL images using the 'Screen' blend mode.
Both images must be RGB or RGBA and will be resized to match the size of image1 if needed.</p></div>
</dd>
<dt id="machina.pixel.picture.superimpose_pictures"><code class="name flex">
<span>def <span class="ident">superimpose_pictures</span></span>(<span>picture_1, picture_2)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def superimpose_pictures(picture_1, picture_2):
    &#34;&#34;&#34;
    Superimpose Two Pictures

    This function overlays one picture on top of another, using the alpha channel of the second image
    to determine transparency. The second image is pasted on top of the first one, and the result is returned
    as a new `Picture`.

    Args:
        picture_1 (Picture): The base image onto which the second image will be pasted.
        picture_2 (Picture): The image to be superimposed on top of the first image.

    Returns:
        Picture: A new `Picture` object with the second image superimposed on top of the first image.

    Example:
        &gt;&gt;&gt; picture_1 = Picture(image1_data)
        &gt;&gt;&gt; picture_2 = Picture(image2_data)
        &gt;&gt;&gt; superimposed_picture = superimpose_pictures(picture_1, picture_2)

    Notes:
        - The function assumes that `picture_2` has an alpha channel (RGBA) for transparency.
        - The superimposition is done at the (0, 0) coordinate, aligning the top-left corners of the two images.
        - This function does not modify the original `picture_1`, instead it returns a new `Picture` with the superimposed images.
    &#34;&#34;&#34;
    picture_1 = picture_1.copy()
    picture_1.image.paste(picture_2.image, (0, 0), picture_2.image)
    return picture_1</code></pre>
</details>
<div class="desc"><p>Superimpose Two Pictures</p>
<p>This function overlays one picture on top of another, using the alpha channel of the second image
to determine transparency. The second image is pasted on top of the first one, and the result is returned
as a new <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>picture_1</code></strong> :&ensp;<code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd>The base image onto which the second image will be pasted.</dd>
<dt><strong><code>picture_2</code></strong> :&ensp;<code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd>The image to be superimposed on top of the first image.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd>A new <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> object with the second image superimposed on top of the first image.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; picture_1 = Picture(image1_data)
&gt;&gt;&gt; picture_2 = Picture(image2_data)
&gt;&gt;&gt; superimposed_picture = superimpose_pictures(picture_1, picture_2)
</code></pre>
<h2 id="notes">Notes</h2>
<ul>
<li>The function assumes that <code>picture_2</code> has an alpha channel (RGBA) for transparency.</li>
<li>The superimposition is done at the (0, 0) coordinate, aligning the top-left corners of the two images.</li>
<li>This function does not modify the original <code>picture_1</code>, instead it returns a new <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> with the superimposed images.</li>
</ul></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="machina.pixel.picture.Picture"><code class="flex name class">
<span>class <span class="ident">Picture</span></span>
<span>(</span><span>image)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Picture:
    &#34;&#34;&#34;
    # Picture Class

    The `Picture` class represent images.
    &#34;&#34;&#34;

    def __init__(self, image):
        self.image = image

    
    def __str__(self):
        return f&#34;&lt;Picture: {self.image.width}x{self.image.height} image&gt;&#34;


    def _repr_png_(self):
        with io.BytesIO() as buf:
            self.image.save(buf, format=&#39;PNG&#39;)
            return buf.getvalue()
        
    


    
    # Constructors
    @classmethod
    def from_file_path(cls, image_path: str):
        &#34;&#34;&#34;
        Create a `Picture` object from an image file.

        Args:
            image_path (str): File path of the image.

        Returns:
            `Picture`
        &#34;&#34;&#34;
        image = Image.open(image_path)
        return cls(image)





    @classmethod
    def from_PIL_image(cls, image):
        &#34;&#34;&#34;
        Create a `Picture`object from a PIL image.

        Args:
            image (PIL.Image): PIL Image object

        Returns:
            `Picture`
        &#34;&#34;&#34;
        return cls(image)






    @classmethod
    def from_array(cls, array):
        &#34;&#34;&#34;
        Convert a NumPy Array to a Picture Object

        Args:
            array (np.ndarray): A NumPy array representing an image, which will be converted into a PIL image.

        Returns:
            Picture: `Picture`

        &#34;&#34;&#34;
        pil_image = Image.fromarray(array)
        return cls(pil_image)







    @property
    def size(self) -&gt; tuple:
        &#34;&#34;&#34;
        This property returns the dimensions (width, height) of the image.

        Returns:
            tuple: A tuple containing two integers representing the width and height of the image.

        Example:
            &gt;&gt;&gt; picture = Picture(image)
            &gt;&gt;&gt; print(picture.size)
            (width, height)
            This will print the size of the image as a tuple.
        &#34;&#34;&#34;
        return self.image.size






    @property
    def width(self) -&gt; int:
        &#34;&#34;&#34;
        Returns the `width` of the image.

        Returns:
            int: The width of the image.
        &#34;&#34;&#34;
        return self.image.size[0]






    @property
    def height(self) -&gt; int:
        &#34;&#34;&#34;
        Returns the `height` of the image.

        Returns:
            int: The height of the image.
        &#34;&#34;&#34;
        return self.image.size[1]






    @property
    def entropy(self) -&gt; float:
        &#34;&#34;&#34;
        Return the `entropy` of the image.

        Returns:
            float: The `entropy` of the image.
        &#34;&#34;&#34;
        return self.image.entropy()






    @property
    def mode(self):
        &#34;&#34;&#34;
        Returns the color mode of the image, such as &#34;RGB&#34;, &#34;RGBA&#34;, &#34;L&#34;, etc.

        Returns:
            str: The mode of the image, which represents the color system used.

        Example:
            &gt;&gt;&gt; picture = Picture(image)
            &gt;&gt;&gt; print(picture.mode)
            &#39;RGB&#39;
            This will print the mode of the image.

        Notes:
            - The mode is a string that indicates the image&#39;s color space.
            - Common modes include &#34;RGB&#34;, &#34;RGBA&#34;, &#34;L&#34; (grayscale), &#34;P&#34; (palette-based), and more.
        &#34;&#34;&#34;
        return self.image.mode






    @property
    def red_channel(self):
        &#34;&#34;&#34;
        Extract the Red Channel from the Image

        Returns:
            Picture: A Picture object containing the image with only the red channel of the original image.
        &#34;&#34;&#34;
        r_values = self.image.split()[0]
        red_image = Image.merge(&#34;RGB&#34;, (r_values, Image.new(&#34;L&#34;, self.image.size, 0), Image.new(&#34;L&#34;, self.image.size, 0)))
        return Picture.from_PIL_image(red_image)






    @property
    def green_channel(self):
        &#34;&#34;&#34;
        Extract the Green Channel from the Image

        Returns:
            Picture: A Picture object containing the image with only the green channel of the original image.
        &#34;&#34;&#34;
        g_values = self.image.split()[1]
        green_image = Image.merge(&#34;RGB&#34;, (Image.new(&#34;L&#34;, self.image.size, 0), g_values, Image.new(&#34;L&#34;, self.image.size, 0)))
        return Picture.from_PIL_image(green_image)






    @property
    def blue_channel(self):
        &#34;&#34;&#34;
        Extract the Blue Channel from the Image

        Returns:
            Picture: A Picture object containing the image with only the blue channel of the original image.
        &#34;&#34;&#34;
        b_values = self.image.split()[2]
        blue_image = Image.merge(&#34;RGB&#34;, (Image.new(&#34;L&#34;, self.image.size, 0), Image.new(&#34;L&#34;, self.image.size, 0), b_values))
        return Picture.from_PIL_image(blue_image)






    @property
    def np_array(self):
        &#34;&#34;&#34;
        The numpy array of the image.

        Returns:
            np.ndarray: A NumPy array representing the image, with shape (height, width, channels) for RGB images.

        &#34;&#34;&#34;
        image_np = np.array(self.image)
        return image_np






    # General methods
    def show(self):
        &#34;&#34;&#34;
        Displays the image using the default image viewer.
        &#34;&#34;&#34;
        self.image.show()





    def save(self, output_path):
        &#34;&#34;&#34;
        Saves the image to a file.

        Args:
            output_path (str): The pathe on which to save the image.
        &#34;&#34;&#34;
        self.image.save(output_path)





    def copy(self):
        &#34;&#34;&#34;
        Return a copy of the `Picture` instance.
        &#34;&#34;&#34;
        return Picture.from_PIL_image(self.image.copy())





    def convert_to_grayscale(self):
        &#34;&#34;&#34;
        Converts the image mode to grayscale (L).
        &#34;&#34;&#34;
        self.image = self.image.convert(&#39;L&#39;)





    def convert_to_rgb(self):
        &#34;&#34;&#34;
        Convert the image mode to RGB.
        &#34;&#34;&#34;
        self.image = self.image.convert(&#39;RGB&#39;)





    def convert_to_rgba(self):
        &#34;&#34;&#34;
        Convert the image mode to RGBA
        &#34;&#34;&#34;
        self.image = self.image.convert(&#39;RGBA&#39;)





    def adjust_brightness(self, value: float):
        &#34;&#34;&#34;
        Adjusts the exposurte of the image.
         - (1.0 = original, &gt;1.0 = brighter, &lt;1.0 = darker)

        Args:
            value (float): adjustment factor of the exposure.

        &#34;&#34;&#34;
        enhancer = ImageEnhance.Brightness(self.image)
        enhanced_image = enhancer.enhance(value)
        self.image = enhanced_image





    def adjust_contrast(self, value: float):
        &#34;&#34;&#34;
        Adjusts the contrast of the image.
         - (1.0 = original, &gt;1.0 = more contrast, &lt;1.0 = less contrast)

        Args:
            value (float): adjustment factor of the contrast.

        &#34;&#34;&#34;
        enhancer = ImageEnhance.Contrast(self.image)
        enhanced_image = enhancer.enhance(value)
        self.image = enhanced_image





    def adjust_sharpness(self, value: float):
        &#34;&#34;&#34;
        Adjusts the sharpness of the image.
         - (1.0 = original, &gt;1.0 = sharper, &lt;1.0 = duller)

        Args:
            value (float): adjustment factor of the sharpness.

        &#34;&#34;&#34;
        enhancer = ImageEnhance.Sharpness(self.image)
        enhanced_image = enhancer.enhance(value)
        self.image = enhanced_image





    def adjust_saturation(self, value: float):
        &#34;&#34;&#34;
        Adjusts the saturation of the image.
         - (1.0 = original, &gt;1.0 = more saturated, &lt;1.0 = less saturated)

        Args:
            value (float): adjustment factor of the saturation.

        &#34;&#34;&#34;
        enhancer = ImageEnhance.Color(self.image)
        enhanced_image = enhancer.enhance(value)
        self.image = enhanced_image




    def get_pixel_color(self, coord_x: int, coord_y: int) -&gt; Color:
        &#34;&#34;&#34;
        Get the color of a pixel at the specified coordinates (coord_x, coord_y).
        
        Args:
            coord_x (int): The x-coordinate of the pixel.
            coord_y (int): The y-coordinate of the pixel.
        
        Returns:
            Color: The color of the pixel as a Color object.
        
        Raises:
            ValueError: If the pixel format is unexpected.
        &#34;&#34;&#34;
        pixel_value = self.image.getpixel((coord_x, coord_y))

        if isinstance(pixel_value, int):  # Grayscale
            return Color(pixel_value, pixel_value, pixel_value)
        elif isinstance(pixel_value, tuple):
            if len(pixel_value) &gt;= 3:
                return Color(pixel_value[0], pixel_value[1], pixel_value[2])
            # Handle other tuple lengths if needed

        # Fallback or raise an error
        raise ValueError(f&#34;Unexpected pixel format: {pixel_value}&#34;)




    # Geometry
    def rotate(self, angle):
        &#34;&#34;&#34;
        Rotates the image by the `angle` expressed in degrees.

        Args:
            angle (float): angle of rotation in degrees
        &#34;&#34;&#34;
        self.image = self.image.rotate(angle)





    def resize(self, width, height, keep_aspect_ratio = True, crop = False):
        &#34;&#34;&#34;
        Resizes the image according to the specified width and height, with options to maintain
        the aspect ratio and/or crop the image. Different resizing methods are used depending on the combination
        of options chosen.

        Args:
            width (int): The target width of the resized image.
            height (int): The target height of the resized image.
            keep_aspect_ratio (bool, optional): Whether to preserve the original aspect ratio of the image.
                                                Defaults to True. If True, the image is resized to fit within the
                                                specified dimensions.
                                                If False, the image is resized to exactly match the target dimensions.
            crop (bool, optional): Whether to crop the image to fit the specified dimensions. Defaults to False.
                                If True, the image will be cropped to maintain the aspect ratio after resizing
                                (used when `keep_aspect_ratio` is also True).
        &#34;&#34;&#34;
        if keep_aspect_ratio and not crop:
            self.image = ImageOps.cover(self.image, (width, height))
        if (keep_aspect_ratio and crop) or crop:
            self.image = ImageOps.fit(self.image, (width, height))
        if not keep_aspect_ratio and not crop:
            self.image = self.image.resize((width, height))





    def crop(self, left_margin, top_margin, right_margin, bottom_margin):
        &#34;&#34;&#34;
        Crops the image by removing the specified margins from the left, top, right, and bottom edges.

        Args:
            left_margin (int): The number of pixels to remove from the left edge of the image.
            top_margin (int): The number of pixels to remove from the top edge of the image.
            right_margin (int): The number of pixels to remove from the right edge of the image.
            bottom_margin (int): The number of pixels to remove from the bottom edge of the image.

        Example:
            &gt;&gt;&gt; picture = Picture(image)
            &gt;&gt;&gt; picture.crop(50, 30, 50, 30)
            This will crop the image by removing 50 pixels from the left, 30 from the top, 50 from the right,
            and 30 from the bottom.
        &#34;&#34;&#34;
        width, height = self.size
        self.image = self.image.crop((left_margin, top_margin, width - right_margin, height - bottom_margin))





    def flip_horizontal(self):
        &#34;&#34;&#34;
        Flips the image horizontally.
        &#34;&#34;&#34;
        self.image = ImageOps.mirror(self.image)





    def flip_vertical(self):
        &#34;&#34;&#34;
        Flips the image vertically.
        &#34;&#34;&#34;
        self.image = ImageOps.flip(self.image)







    def get_main_colors(self, num_colors) -&gt; list[Color]:
        &#34;&#34;&#34;
        Return a list of the main $n$ colors of the image.

        Args:
            num_colors (int): number of main colors to return

        Returns:
            list[Color]: list of HAL.pixels.Color objects.
        &#34;&#34;&#34;
        # Convert image to &#34;P&#34; mode (palette-based) with an adaptive palette
        image = self.image.convert(&#34;P&#34;, palette=Image.Palette.ADAPTIVE, colors=num_colors)

        # Get the palette (a list of RGB values, where every 3 values are an (R, G, B) triplet)
        palette = image.getpalette()
        if palette is None:
            return []

        palette = palette[:num_colors * 3]  # Only get requested number of colors

        # Convert flat list to list of RGB tuples
        colors = [tuple(palette[i:i+3]) for i in range(0, len(palette), 3)]
        colors = [Color(c[0], c[1], c[2]) for c in colors]
        return colors





    def get_color_palette(self, num_colors):
        &#34;&#34;&#34;
        Return a `Picture` of the colorpalette of the image.

        Args:
            num_colors (int): number of colors to include in the color palette.

        Returns:
            Picture: color palette of the picture.
        &#34;&#34;&#34;
        colors = self.get_main_colors(num_colors)
        color_pictures = []
        for color in colors:
            color_pictures.append(Picture.from_PIL_image(Image.new(&#39;RGB&#39;, (100, 100), color.rgb)))
        palette = create_grid_of_pictures(color_pictures, grid_size=(num_colors, 1), image_size=(100, 100))
        return palette





    # Dithering methods

    def dither_halftone(self, **kwargs):
        &#34;&#34;&#34;
        Apply a Halftone Dither Effect to the Image

        This method converts the image to grayscale and applies a halftone dithering effect,
        where the brightness of the image is represented using dots of varying sizes. The dots
        are placed in a grid pattern, with darker areas having larger dots and lighter areas
        having smaller dots.

        Args:
            dot_color (Color, optional): The color of the halftone dots. Defaults to black.
            background_color (Color, optional): The background color for the image. Defaults to white.
            dot_spacing (int, optional): The spacing between the dots in the grid. Defaults to 12 pixels.
            dot_size (int, optional): The maximum size of the dots. Defaults to 8 pixels.

        Returns:
            None

        Example:
            &gt;&gt;&gt; picture = Picture(image)
            &gt;&gt;&gt; picture.dither_halftone(dot_color=RED, background_color=WHITE, dot_spacing=10, dot_size=5)
            This will apply a halftone dithering effect with red dots, a white background, and customized spacing and dot size.

        Notes:
            - The image is first converted to grayscale before applying the halftone effect.
            - The brightness of each pixel determines the size of the dots, with darker areas having larger dots.
            - The method uses a grid pattern with adjustable dot spacing and size to create the halftone effect.

        &#34;&#34;&#34;
        # Kwargs
        dot_color = kwargs.get(&#39;dot_color&#39;, Color.BLACK)
        background_color = kwargs.get(&#39;background_color&#39;, Color.WHITE)
        dot_spacing = kwargs.get(&#39;dot_spacing&#39;, 12)
        dot_size = kwargs.get(&#39;dot_size&#39;, 8)

        # Open image and convert to grayscale
        self.convert_to_grayscale()
        width, height = self.size
        halftone = Image.new(&#39;RGB&#39;, (width, height), background_color.rgb)
        draw = ImageDraw.Draw(halftone)

        # Process image in a grid pattern
        for y in range(0, height, dot_spacing):
            for x in range(0, width, dot_spacing):
                # Get pixel brightness (0-255, where 0 is black and 255 is white)
                pixel_value = self.image.getpixel((x, y))

                # Handle different pixel formats
                if isinstance(pixel_value, int):  # Grayscale
                    brightness = float(pixel_value)
                elif isinstance(pixel_value, tuple) and len(pixel_value) &gt; 0:
                    brightness = float(pixel_value[0])  # Take first channel
                else:
                    brightness = 0.0  # Default if pixel format is unexpected

                # Scale dot size based on brightness (darker areas have larger dots)
                radius = (1 - brightness / 255) * dot_size / 2

                if radius &gt; 0:
                    draw.ellipse((x - radius, y - radius, x + radius, y + radius), fill=dot_color.rgb)

        self.image = halftone






    def dither_ordered(self, **kwargs):
        &#34;&#34;&#34;
        Apply Ordered Dithering to the Image using Bayer Matrix

        This method applies ordered dithering to an image using a Bayer matrix, which is a technique
        to convert grayscale images to a binary representation using a threshold map. The method
        divides the image into a grid pattern and uses a Bayer matrix of a specified size to
        determine the threshold for dithering.

        Args:
            matrix_size (int, optional): The size of the Bayer matrix to use for dithering.
                                        Supported values are 2, 4, or 8. Defaults to 8.
            scale_factor (int, optional): The size of the grid to process in the dithering.
                                        Defaults to 5 pixels.
            color (Color, optional): The color for the &#34;on&#34; pixels in the dithering (typically white).
                                    Defaults to white.
            background_color (Color, optional): The color for the &#34;off&#34; pixels in the dithering (typically black).
                                                Defaults to black.

        Returns:
            None

        Example:
            &gt;&gt;&gt; picture = Picture(image)
            &gt;&gt;&gt; picture.dither_ordered(matrix_size=4, scale_factor=6, color=WHITE, background_color=BLACK)
            This will apply ordered dithering to the image using a 4x4 Bayer matrix,
            with a scale factor of 6 pixels for each grid and white for the &#34;on&#34; color.

        Notes:
            - The Bayer matrices of size 2, 4, and 8 are pre-defined, and the dithering is based on the threshold values
            derived from these matrices.
            - The method processes the image in blocks of the specified `scale_factor` and applies the dithering based on
            pixel brightness in relation to the corresponding threshold in the Bayer matrix.
        &#34;&#34;&#34;
        # Kwargs
        matrix_size = kwargs.get(&#39;matrix_size&#39;, 8)
        scale_factor = kwargs.get(&#39;scale_factor&#39;, 5)
        color = kwargs.get(&#39;color&#39;, Color.WHITE)
        background_color = kwargs.get(&#39;background_color&#39;, Color.BLACK)

        # Bayer matrices of different sizes
        bayer_matrices = {
            2: np.array([[0, 2], [3, 1]]) / 4.0,
            4: np.array([[0, 8, 2, 10], [12, 4, 14, 6], [3, 11, 1, 9], [15, 7, 13, 5]]) / 16.0,
            8: np.array([
                [0, 32, 8, 40, 2, 34, 10, 42],
                [48, 16, 56, 24, 50, 18, 58, 26],
                [12, 44, 4, 36, 14, 46, 6, 38],
                [60, 28, 52, 20, 62, 30, 54, 22],
                [3, 35, 11, 43, 1, 33, 9, 41],
                [51, 19, 59, 27, 49, 17, 57, 25],
                [15, 47, 7, 39, 13, 45, 5, 37],
                [63, 31, 55, 23, 61, 29, 53, 21]
            ]) / 64.0
        }

        if matrix_size not in bayer_matrices:
            raise ValueError(&#34;Unsupported matrix size. Choose from 2, 4, or 8.&#34;)

        bayer_matrix = bayer_matrices[matrix_size]
        threshold_map = (bayer_matrix * 255).astype(np.uint8)

        # Open image and convert to grayscale
        self.convert_to_grayscale()
        width, height = self.image.size
        pixels = np.array(self.image, dtype=np.uint8)

        # Convert image to RGB to sore colore pixels
        color_pixels = np.zeros((height, width, 3), dtype=np.uint8)

        # Apply dithering
        for y in range(0, height, scale_factor):
            for x in range(0, width, scale_factor):
                threshold = threshold_map[(y // scale_factor) % matrix_size, (x // scale_factor) % matrix_size]
                color_pixels[y:y+scale_factor, x:x+scale_factor] = color.rgb if pixels[y, x] &gt; threshold else background_color.rgb

        dithered_image = Image.fromarray(color_pixels, mode=&#39;RGB&#39;)
        self.image =  dithered_image






    def dither_floyd_steinberg(self, **kwargs):
        &#34;&#34;&#34;
        Apply Floyd-Steinberg Dithering to the Image

        This method applies the Floyd-Steinberg dithering algorithm, a popular error-diffusion technique
        used to convert grayscale images into a binary representation while preserving the appearance of
        continuous tones. The method scales the image, applies the dithering, and then resizes it back to
        the original size.

        Args:
            scale_factor (int, optional): The scaling factor for the image before applying the dithering.
                                        A larger value reduces the amount of scaling applied to the image.
                                        Defaults to 3.

        Returns:
            None

        Example:
            &gt;&gt;&gt; picture = Picture(image)
            &gt;&gt;&gt; picture.dither_floyd_steinberg(scale_factor=4)
            This will apply Floyd-Steinberg dithering to the image with a scale factor of 4.

        Notes:
            - The image is first converted to grayscale before applying the dithering.
            - The algorithm works by diffusing the error between the pixel value and the nearest threshold
            (either 0 or 255) to neighboring pixels.
            - The image is scaled down by the specified `scale_factor` to speed up the dithering process,
            and then scaled back to the original dimensions after dithering.
            - The error diffusion weights for the Floyd-Steinberg algorithm are as follows:
            - (7/16) to the pixel to the right
            - (3/16) to the pixel below-left
            - (5/16) to the pixel below
            - (1/16) to the pixel below-right
        &#34;&#34;&#34;

        scale_factor = kwargs.get(&#39;scale_factor&#39;, 3)

        self.convert_to_grayscale()
        pixels = np.array(self.image, dtype=np.float32)
        height, width = pixels.shape

        scaled_height = int(height / scale_factor)
        scaled_width = int(width / scale_factor)
        scaled_image = Image.fromarray(pixels.astype(np.uint8)).resize((scaled_width, scaled_height), Image.Resampling.NEAREST)
        pixels = np.array(scaled_image, dtype=np.float32)

        for y in range(scaled_height):
            for x in range(scaled_width):
                old_pixel = pixels[y, x]
                new_pixel = 255 if old_pixel &gt; 127 else 0
                pixels[y, x] = new_pixel
                quant_error = old_pixel - new_pixel

                if x &lt; scaled_width - 1:
                    pixels[y, x + 1] += quant_error * (7 / 16)
                if y &lt; scaled_height - 1:
                    if x &gt; 0:
                        pixels[y + 1, x - 1] += quant_error * (3 / 16)
                    pixels[y + 1, x] += quant_error * (5 / 16)
                    if x &lt; scaled_width - 1:
                        pixels[y + 1, x + 1] += quant_error * (1 / 16)

        dithered_image = Image.fromarray(np.clip(pixels, 0, 255).astype(np.uint8), mode=&#39;L&#39;)
        dithered_image = dithered_image.resize((width, height), Image.Resampling.NEAREST)
        self.image = dithered_image




    # OTHER OPERATIONS

    def binarize(self, **kwargs):
        &#34;&#34;&#34;
        Convert the Image to Binary (Black and White) using a Threshold

        This method converts the image into a binary image, where each pixel is either black or white,
        based on a specified threshold. The method also allows for color customization when the image
        is in color mode, and it includes options for converting the image to grayscale or color before
        applying the threshold.

        Args:
            threshold (int, optional): The pixel intensity threshold used to decide whether a pixel becomes
                                        white (255) or black (0). Values greater than the threshold will be
                                        set to white. Default is 128.
            grayscale (bool, optional): If True, the image will be converted to grayscale before binarization.
                                        Default is True.
            color (Color, optional): A color to replace black pixels in the image when `grayscale` is False.
                                    If None, the black pixels will remain black. Default is None.

        Returns:
            None: The method modifies the image in place, converting it to binary (black and white).

        Example:
            &gt;&gt;&gt; picture = Picture(image)
            &gt;&gt;&gt; picture.binarize(threshold=100, grayscale=False, color=RED)
            This will binarize the image with a threshold of 100, and replace black pixels with red color.

        Notes:
            - If `grayscale` is True or `color` is specified, the image is first converted to grayscale.
            - The image is processed pixel by pixel, and each pixel value is compared to the threshold.
            If the pixel value is above the threshold, it is set to white (255), and if it is below, it is
            set to black (0).
            - If `color` is specified, black pixels will be replaced with the given color.
        &#34;&#34;&#34;

        threshold = kwargs.get(&#34;threshold&#34;, 128)
        grayscale = kwargs.get(&#34;grayscale&#34;, True)
        color = kwargs.get(&#34;color&#34;, None)

        if grayscale or color:
            self.convert_to_grayscale()

        binarized_image = self.image.point(lambda p: 255 if p &gt; threshold else 0)
        self.image = binarized_image

        if color:
            self.convert_to_rgb()
            pixels = self.image.load()  # This returns an object that can be indexed, not None
            if pixels is not None:  # Add a check to ensure pixels is not None
                for y in range(self.image.height):
                    for x in range(self.image.width):
                        if pixels[x, y] == (0, 0, 0):
                            pixels[x, y] = color.rgb





    # MASKS

    def create_alpha_mask(self):
        &#34;&#34;&#34;
        Create an Alpha Mask for the Image

        This method generates an alpha mask for the image, where pixels with a value of 0 (black)
        are set to fully transparent (alpha = 0) and non-zero pixels are set to partially transparent
        (alpha = 1). It creates an RGBA image with the alpha channel representing the mask.

        The image is first copied and then processed to create an RGBA version where the alpha channel
        is set based on the binarized pixel values. After creating the mask, the image is converted
        back to grayscale.

        Returns:
            None

        Notes:
            - The method assumes that the image is already in a format that can be binarized.
            - The alpha mask is based on the binary representation of the image.
            - The image is processed pixel by pixel, and an RGBA image is created.
        &#34;&#34;&#34;
        binarized_image = self.copy()
        self.convert_to_rgba()
        for y in range(self.image.height):
            for x in range(self.image.width):
                pixel_value = binarized_image.image.getpixel((x, y))
                if pixel_value == 0:
                    self.image.putpixel((x, y), (255, 255, 255, 0))
                else:
                    self.image.putpixel((x, y), (0, 0, 0, 1))
        self.convert_to_grayscale()







    def apply_alpha_mask(self, mask):
        &#34;&#34;&#34;
        Apply an Alpha Mask to the Image

        This method applies an alpha mask to the current image. The alpha mask should be a binary image
        (with an alpha channel) that defines transparency values for the image. The mask is applied by
        setting the alpha channel of the current image according to the mask&#39;s alpha channel.

        The method expects that the mask is a `Picture` object with an image that contains an alpha channel.
        It uses the alpha values of the mask to modify the transparency of the original image.

        Args:
            mask (Picture): A `Picture` object that contains the alpha mask to be applied.
                            The mask image should be in RGBA mode.

        Returns:
            None

        Example:
            &gt;&gt;&gt; picture = Picture(image)
            &gt;&gt;&gt; alpha_mask = Picture(mask_image)
            &gt;&gt;&gt; picture.apply_alpha_mask(alpha_mask)
            This will apply the alpha mask to the original image, altering its transparency based on the mask.

        Notes:
            - The mask should be an RGBA image where the alpha channel defines transparency.
            - The current image must be in a format that supports an alpha channel (e.g., RGBA).
        &#34;&#34;&#34;
        self.image.putalpha(mask.image)






    def paste_picture(self, picture_to_paste, coord_x: int, coord_y: int):
        &#34;&#34;&#34;
        Paste one picture onto another at the specified coordinates while handling transparency.
        
        Args:
            picture_to_paste (Picture): The picture to be pasted.
            coord_x (int): The x-coordinate where the picture should be pasted.
            coord_y (int): The y-coordinate where the picture should be pasted.
        &#34;&#34;&#34;
        mask = picture_to_paste.copy()
        mask.convert_to_rgba()
        self.image.paste(picture_to_paste.image, (coord_x, coord_y), mask.image)





    # Filters
    def blur(self, radius: float):
        &#34;&#34;&#34;
        Apply a Gaussian Blur to the Image

        This method applies a Gaussian blur filter to the current image, which softens the image by
        averaging nearby pixels. The intensity of the blur is determined by the radius parameter.
        Larger values for the radius will result in a stronger blur effect.

        Args:
            radius (float): The radius of the blur. A higher radius value results in a more blurred image.

        Returns:
            None
        &#34;&#34;&#34;
        self.image = self.image.filter(ImageFilter.GaussianBlur(radius))




    def invert_colors(self):
        &#34;&#34;&#34;
        Invert the Colors of the Image

        This method inverts the colors of the current image, transforming all pixels in the image
        to their complementary color. Each pixel&#39;s red, green, and blue values are inverted, meaning
        that the color channels are flipped to their opposite values. For example, a white pixel (255, 255, 255)
        would become black (0, 0, 0), and vice versa.

        Args:
            None: This method operates directly on the current image.

        Returns:
            None
        &#34;&#34;&#34;
        self.image = ImageOps.invert(self.image)





    def apply_color_filter(self, color):
        &#34;&#34;&#34;
        This method applies a color filter to the current image by multiplying the image with a solid color.
        The resulting image will have a tint of the provided color, blending the original image with the filter color.

        Args:
            color (Color): The `Color` object representing the filter color. This color will be multiplied
                        with each pixel in the image to apply the filter effect.

        Returns:
            None
        &#34;&#34;&#34;
        color_filter = Image.new(&#34;RGB&#34;, self.image.size, color.rgb)
        self.image = ImageChops.multiply(self.image, color_filter)











    # DRAWING 


    def draw_line(self, start: tuple, end: tuple, **kwargs) -&gt; None:
        &#34;&#34;&#34;
        Draw a line between two points on the image.
        
        Args:
            start (tuple): The starting point of the line (x1, y1).
            end (tuple): The ending point of the line (x2, y2).
            width (int, optional): The width of the line. Defaults to 3.
            **kwargs: Optional keyword arguments for customization. 
                    - &#39;color&#39; (Color): The color of the line. Defaults to `WHITE`.
                    - &#39;width&#39; (int): The width of the line. Defaults to 3.
        
        Returns:
            None
        &#34;&#34;&#34;
        color = kwargs.get(&#39;color&#39;, Color.WHITE)
        width = kwargs.get(&#39;width&#39;, 3)

        draw = ImageDraw.Draw(self.image)
        draw.line([start, end], fill=color.rgb, width=width)




    def draw_circle(self, center: tuple[int, int], radius: int, **kwargs) -&gt; None:
        &#34;&#34;&#34;
        Draw a circle on the image with the given center and radius.
        
        Args:
            center (tuple): The center point of the circle (x, y).
            radius (int): The radius of the circle.
            **kwargs: Optional keyword arguments for customization.
                    - &#39;color&#39;: The color of the circle. Defaults to `WHITE`.
        
        Returns:
            None
        &#34;&#34;&#34;
        color: Color = kwargs.get(&#39;color&#39;, Color.WHITE)

        draw = ImageDraw.Draw(self.image)
        x, y = center
        bounding_box = [x - radius, y - radius, x + radius, y + radius]
        draw.ellipse(bounding_box, width=5, fill=color.rgb)





    def draw_text(self, text: str, position: tuple[int, int], font_size, **kwargs) -&gt; None:
        &#34;&#34;&#34;
        Draw text on the image at the specified position with the given font size.
        
        Args:
            text (str): The text to be drawn.
            position (tuple): The (x, y) position where the text&#39;s baseline will be.
            font_size (int): The font size.
            **kwargs: Optional keyword arguments for customization.
                    - &#39;color&#39;: The color of the text. Defaults to `Color.BLACK`.
        
        Returns:
            None
        &#34;&#34;&#34;
        color = kwargs.get(&#39;color&#39;,Color.BLACK)

        draw = ImageDraw.Draw(self.image)
        font_path = os.path.join(os.path.dirname(__file__), &#39;..&#39;, &#39;fonts&#39;, &#39;font_test.ttf&#39;)
        font = ImageFont.truetype(font_path, font_size)

        # Measure text size
        bbox = draw.textbbox((0, 0), text, font=font)
        text_width = bbox[2] - bbox[0]
        text_height = bbox[3] - bbox[1]

        # Adjust position if centering
        x, y = position
        x -= text_width // 2
        y -= text_height // 2

        draw.text((x, y), text, fill=color.rgb, font=font)





    def draw_arrow(self, start: tuple, end: tuple, width=3, arrowhead_length=50, arrowhead_angle=30, **kwargs) -&gt; None:
        color = kwargs.get(&#39;color&#39;, Color.WHITE)

        draw = ImageDraw.Draw(self.image)

        # Draw the main shaft
        draw.line([start, end], fill=color.rgb, width=width)

        # Direction vector
        dx = end[0] - start[0]
        dy = end[1] - start[1]
        angle = math.atan2(dy, dx)

        # Arrowhead points
        left_angle = angle + math.radians(arrowhead_angle)
        right_angle = angle - math.radians(arrowhead_angle)

        left_point = (
            end[0] - arrowhead_length * math.cos(left_angle),
            end[1] - arrowhead_length * math.sin(left_angle)
        )
        right_point = (
            end[0] - arrowhead_length * math.cos(right_angle),
            end[1] - arrowhead_length * math.sin(right_angle)
        )

        # Draw filled triangle for arrowhead
        draw.polygon([end, left_point, right_point], fill=color.rgb)</code></pre>
</details>
<div class="desc"><h1 id="picture-class">Picture Class</h1>
<p>The <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> class represent images.</p></div>
<h3>Static methods</h3>
<dl>
<dt id="machina.pixel.picture.Picture.from_PIL_image"><code class="name flex">
<span>def <span class="ident">from_PIL_image</span></span>(<span>image)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code>object from a PIL image.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>PIL.Image</code></dt>
<dd>PIL Image object</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></p></div>
</dd>
<dt id="machina.pixel.picture.Picture.from_array"><code class="name flex">
<span>def <span class="ident">from_array</span></span>(<span>array)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert a NumPy Array to a Picture Object</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>array</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>A NumPy array representing an image, which will be converted into a PIL image.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd><code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.from_file_path"><code class="name flex">
<span>def <span class="ident">from_file_path</span></span>(<span>image_path: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> object from an image file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image_path</code></strong> :&ensp;<code>str</code></dt>
<dd>File path of the image.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></p></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="machina.pixel.picture.Picture.blue_channel"><code class="name">prop <span class="ident">blue_channel</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def blue_channel(self):
    &#34;&#34;&#34;
    Extract the Blue Channel from the Image

    Returns:
        Picture: A Picture object containing the image with only the blue channel of the original image.
    &#34;&#34;&#34;
    b_values = self.image.split()[2]
    blue_image = Image.merge(&#34;RGB&#34;, (Image.new(&#34;L&#34;, self.image.size, 0), Image.new(&#34;L&#34;, self.image.size, 0), b_values))
    return Picture.from_PIL_image(blue_image)</code></pre>
</details>
<div class="desc"><p>Extract the Blue Channel from the Image</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd>A Picture object containing the image with only the blue channel of the original image.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.entropy"><code class="name">prop <span class="ident">entropy</span> : float</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def entropy(self) -&gt; float:
    &#34;&#34;&#34;
    Return the `entropy` of the image.

    Returns:
        float: The `entropy` of the image.
    &#34;&#34;&#34;
    return self.image.entropy()</code></pre>
</details>
<div class="desc"><p>Return the <code>entropy</code> of the image.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>The <code>entropy</code> of the image.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.green_channel"><code class="name">prop <span class="ident">green_channel</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def green_channel(self):
    &#34;&#34;&#34;
    Extract the Green Channel from the Image

    Returns:
        Picture: A Picture object containing the image with only the green channel of the original image.
    &#34;&#34;&#34;
    g_values = self.image.split()[1]
    green_image = Image.merge(&#34;RGB&#34;, (Image.new(&#34;L&#34;, self.image.size, 0), g_values, Image.new(&#34;L&#34;, self.image.size, 0)))
    return Picture.from_PIL_image(green_image)</code></pre>
</details>
<div class="desc"><p>Extract the Green Channel from the Image</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd>A Picture object containing the image with only the green channel of the original image.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.height"><code class="name">prop <span class="ident">height</span> : int</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def height(self) -&gt; int:
    &#34;&#34;&#34;
    Returns the `height` of the image.

    Returns:
        int: The height of the image.
    &#34;&#34;&#34;
    return self.image.size[1]</code></pre>
</details>
<div class="desc"><p>Returns the <code>height</code> of the image.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The height of the image.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.mode"><code class="name">prop <span class="ident">mode</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def mode(self):
    &#34;&#34;&#34;
    Returns the color mode of the image, such as &#34;RGB&#34;, &#34;RGBA&#34;, &#34;L&#34;, etc.

    Returns:
        str: The mode of the image, which represents the color system used.

    Example:
        &gt;&gt;&gt; picture = Picture(image)
        &gt;&gt;&gt; print(picture.mode)
        &#39;RGB&#39;
        This will print the mode of the image.

    Notes:
        - The mode is a string that indicates the image&#39;s color space.
        - Common modes include &#34;RGB&#34;, &#34;RGBA&#34;, &#34;L&#34; (grayscale), &#34;P&#34; (palette-based), and more.
    &#34;&#34;&#34;
    return self.image.mode</code></pre>
</details>
<div class="desc"><p>Returns the color mode of the image, such as "RGB", "RGBA", "L", etc.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The mode of the image, which represents the color system used.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; picture = Picture(image)
&gt;&gt;&gt; print(picture.mode)
'RGB'
This will print the mode of the image.
</code></pre>
<h2 id="notes">Notes</h2>
<ul>
<li>The mode is a string that indicates the image's color space.</li>
<li>Common modes include "RGB", "RGBA", "L" (grayscale), "P" (palette-based), and more.</li>
</ul></div>
</dd>
<dt id="machina.pixel.picture.Picture.np_array"><code class="name">prop <span class="ident">np_array</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def np_array(self):
    &#34;&#34;&#34;
    The numpy array of the image.

    Returns:
        np.ndarray: A NumPy array representing the image, with shape (height, width, channels) for RGB images.

    &#34;&#34;&#34;
    image_np = np.array(self.image)
    return image_np</code></pre>
</details>
<div class="desc"><p>The numpy array of the image.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>A NumPy array representing the image, with shape (height, width, channels) for RGB images.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.red_channel"><code class="name">prop <span class="ident">red_channel</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def red_channel(self):
    &#34;&#34;&#34;
    Extract the Red Channel from the Image

    Returns:
        Picture: A Picture object containing the image with only the red channel of the original image.
    &#34;&#34;&#34;
    r_values = self.image.split()[0]
    red_image = Image.merge(&#34;RGB&#34;, (r_values, Image.new(&#34;L&#34;, self.image.size, 0), Image.new(&#34;L&#34;, self.image.size, 0)))
    return Picture.from_PIL_image(red_image)</code></pre>
</details>
<div class="desc"><p>Extract the Red Channel from the Image</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd>A Picture object containing the image with only the red channel of the original image.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.size"><code class="name">prop <span class="ident">size</span> : tuple</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def size(self) -&gt; tuple:
    &#34;&#34;&#34;
    This property returns the dimensions (width, height) of the image.

    Returns:
        tuple: A tuple containing two integers representing the width and height of the image.

    Example:
        &gt;&gt;&gt; picture = Picture(image)
        &gt;&gt;&gt; print(picture.size)
        (width, height)
        This will print the size of the image as a tuple.
    &#34;&#34;&#34;
    return self.image.size</code></pre>
</details>
<div class="desc"><p>This property returns the dimensions (width, height) of the image.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>A tuple containing two integers representing the width and height of the image.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; picture = Picture(image)
&gt;&gt;&gt; print(picture.size)
(width, height)
This will print the size of the image as a tuple.
</code></pre></div>
</dd>
<dt id="machina.pixel.picture.Picture.width"><code class="name">prop <span class="ident">width</span> : int</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def width(self) -&gt; int:
    &#34;&#34;&#34;
    Returns the `width` of the image.

    Returns:
        int: The width of the image.
    &#34;&#34;&#34;
    return self.image.size[0]</code></pre>
</details>
<div class="desc"><p>Returns the <code>width</code> of the image.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The width of the image.</dd>
</dl></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="machina.pixel.picture.Picture.adjust_brightness"><code class="name flex">
<span>def <span class="ident">adjust_brightness</span></span>(<span>self, value: float)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adjust_brightness(self, value: float):
    &#34;&#34;&#34;
    Adjusts the exposurte of the image.
     - (1.0 = original, &gt;1.0 = brighter, &lt;1.0 = darker)

    Args:
        value (float): adjustment factor of the exposure.

    &#34;&#34;&#34;
    enhancer = ImageEnhance.Brightness(self.image)
    enhanced_image = enhancer.enhance(value)
    self.image = enhanced_image</code></pre>
</details>
<div class="desc"><p>Adjusts the exposurte of the image.
- (1.0 = original, &gt;1.0 = brighter, &lt;1.0 = darker)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>value</code></strong> :&ensp;<code>float</code></dt>
<dd>adjustment factor of the exposure.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.adjust_contrast"><code class="name flex">
<span>def <span class="ident">adjust_contrast</span></span>(<span>self, value: float)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adjust_contrast(self, value: float):
    &#34;&#34;&#34;
    Adjusts the contrast of the image.
     - (1.0 = original, &gt;1.0 = more contrast, &lt;1.0 = less contrast)

    Args:
        value (float): adjustment factor of the contrast.

    &#34;&#34;&#34;
    enhancer = ImageEnhance.Contrast(self.image)
    enhanced_image = enhancer.enhance(value)
    self.image = enhanced_image</code></pre>
</details>
<div class="desc"><p>Adjusts the contrast of the image.
- (1.0 = original, &gt;1.0 = more contrast, &lt;1.0 = less contrast)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>value</code></strong> :&ensp;<code>float</code></dt>
<dd>adjustment factor of the contrast.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.adjust_saturation"><code class="name flex">
<span>def <span class="ident">adjust_saturation</span></span>(<span>self, value: float)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adjust_saturation(self, value: float):
    &#34;&#34;&#34;
    Adjusts the saturation of the image.
     - (1.0 = original, &gt;1.0 = more saturated, &lt;1.0 = less saturated)

    Args:
        value (float): adjustment factor of the saturation.

    &#34;&#34;&#34;
    enhancer = ImageEnhance.Color(self.image)
    enhanced_image = enhancer.enhance(value)
    self.image = enhanced_image</code></pre>
</details>
<div class="desc"><p>Adjusts the saturation of the image.
- (1.0 = original, &gt;1.0 = more saturated, &lt;1.0 = less saturated)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>value</code></strong> :&ensp;<code>float</code></dt>
<dd>adjustment factor of the saturation.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.adjust_sharpness"><code class="name flex">
<span>def <span class="ident">adjust_sharpness</span></span>(<span>self, value: float)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adjust_sharpness(self, value: float):
    &#34;&#34;&#34;
    Adjusts the sharpness of the image.
     - (1.0 = original, &gt;1.0 = sharper, &lt;1.0 = duller)

    Args:
        value (float): adjustment factor of the sharpness.

    &#34;&#34;&#34;
    enhancer = ImageEnhance.Sharpness(self.image)
    enhanced_image = enhancer.enhance(value)
    self.image = enhanced_image</code></pre>
</details>
<div class="desc"><p>Adjusts the sharpness of the image.
- (1.0 = original, &gt;1.0 = sharper, &lt;1.0 = duller)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>value</code></strong> :&ensp;<code>float</code></dt>
<dd>adjustment factor of the sharpness.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.apply_alpha_mask"><code class="name flex">
<span>def <span class="ident">apply_alpha_mask</span></span>(<span>self, mask)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_alpha_mask(self, mask):
    &#34;&#34;&#34;
    Apply an Alpha Mask to the Image

    This method applies an alpha mask to the current image. The alpha mask should be a binary image
    (with an alpha channel) that defines transparency values for the image. The mask is applied by
    setting the alpha channel of the current image according to the mask&#39;s alpha channel.

    The method expects that the mask is a `Picture` object with an image that contains an alpha channel.
    It uses the alpha values of the mask to modify the transparency of the original image.

    Args:
        mask (Picture): A `Picture` object that contains the alpha mask to be applied.
                        The mask image should be in RGBA mode.

    Returns:
        None

    Example:
        &gt;&gt;&gt; picture = Picture(image)
        &gt;&gt;&gt; alpha_mask = Picture(mask_image)
        &gt;&gt;&gt; picture.apply_alpha_mask(alpha_mask)
        This will apply the alpha mask to the original image, altering its transparency based on the mask.

    Notes:
        - The mask should be an RGBA image where the alpha channel defines transparency.
        - The current image must be in a format that supports an alpha channel (e.g., RGBA).
    &#34;&#34;&#34;
    self.image.putalpha(mask.image)</code></pre>
</details>
<div class="desc"><p>Apply an Alpha Mask to the Image</p>
<p>This method applies an alpha mask to the current image. The alpha mask should be a binary image
(with an alpha channel) that defines transparency values for the image. The mask is applied by
setting the alpha channel of the current image according to the mask's alpha channel.</p>
<p>The method expects that the mask is a <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> object with an image that contains an alpha channel.
It uses the alpha values of the mask to modify the transparency of the original image.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>mask</code></strong> :&ensp;<code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd>A <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> object that contains the alpha mask to be applied.
The mask image should be in RGBA mode.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; picture = Picture(image)
&gt;&gt;&gt; alpha_mask = Picture(mask_image)
&gt;&gt;&gt; picture.apply_alpha_mask(alpha_mask)
This will apply the alpha mask to the original image, altering its transparency based on the mask.
</code></pre>
<h2 id="notes">Notes</h2>
<ul>
<li>The mask should be an RGBA image where the alpha channel defines transparency.</li>
<li>The current image must be in a format that supports an alpha channel (e.g., RGBA).</li>
</ul></div>
</dd>
<dt id="machina.pixel.picture.Picture.apply_color_filter"><code class="name flex">
<span>def <span class="ident">apply_color_filter</span></span>(<span>self, color)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_color_filter(self, color):
    &#34;&#34;&#34;
    This method applies a color filter to the current image by multiplying the image with a solid color.
    The resulting image will have a tint of the provided color, blending the original image with the filter color.

    Args:
        color (Color): The `Color` object representing the filter color. This color will be multiplied
                    with each pixel in the image to apply the filter effect.

    Returns:
        None
    &#34;&#34;&#34;
    color_filter = Image.new(&#34;RGB&#34;, self.image.size, color.rgb)
    self.image = ImageChops.multiply(self.image, color_filter)</code></pre>
</details>
<div class="desc"><p>This method applies a color filter to the current image by multiplying the image with a solid color.
The resulting image will have a tint of the provided color, blending the original image with the filter color.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>color</code></strong> :&ensp;<code>Color</code></dt>
<dd>The <code>Color</code> object representing the filter color. This color will be multiplied
with each pixel in the image to apply the filter effect.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
</dd>
<dt id="machina.pixel.picture.Picture.binarize"><code class="name flex">
<span>def <span class="ident">binarize</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def binarize(self, **kwargs):
    &#34;&#34;&#34;
    Convert the Image to Binary (Black and White) using a Threshold

    This method converts the image into a binary image, where each pixel is either black or white,
    based on a specified threshold. The method also allows for color customization when the image
    is in color mode, and it includes options for converting the image to grayscale or color before
    applying the threshold.

    Args:
        threshold (int, optional): The pixel intensity threshold used to decide whether a pixel becomes
                                    white (255) or black (0). Values greater than the threshold will be
                                    set to white. Default is 128.
        grayscale (bool, optional): If True, the image will be converted to grayscale before binarization.
                                    Default is True.
        color (Color, optional): A color to replace black pixels in the image when `grayscale` is False.
                                If None, the black pixels will remain black. Default is None.

    Returns:
        None: The method modifies the image in place, converting it to binary (black and white).

    Example:
        &gt;&gt;&gt; picture = Picture(image)
        &gt;&gt;&gt; picture.binarize(threshold=100, grayscale=False, color=RED)
        This will binarize the image with a threshold of 100, and replace black pixels with red color.

    Notes:
        - If `grayscale` is True or `color` is specified, the image is first converted to grayscale.
        - The image is processed pixel by pixel, and each pixel value is compared to the threshold.
        If the pixel value is above the threshold, it is set to white (255), and if it is below, it is
        set to black (0).
        - If `color` is specified, black pixels will be replaced with the given color.
    &#34;&#34;&#34;

    threshold = kwargs.get(&#34;threshold&#34;, 128)
    grayscale = kwargs.get(&#34;grayscale&#34;, True)
    color = kwargs.get(&#34;color&#34;, None)

    if grayscale or color:
        self.convert_to_grayscale()

    binarized_image = self.image.point(lambda p: 255 if p &gt; threshold else 0)
    self.image = binarized_image

    if color:
        self.convert_to_rgb()
        pixels = self.image.load()  # This returns an object that can be indexed, not None
        if pixels is not None:  # Add a check to ensure pixels is not None
            for y in range(self.image.height):
                for x in range(self.image.width):
                    if pixels[x, y] == (0, 0, 0):
                        pixels[x, y] = color.rgb</code></pre>
</details>
<div class="desc"><p>Convert the Image to Binary (Black and White) using a Threshold</p>
<p>This method converts the image into a binary image, where each pixel is either black or white,
based on a specified threshold. The method also allows for color customization when the image
is in color mode, and it includes options for converting the image to grayscale or color before
applying the threshold.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>threshold</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The pixel intensity threshold used to decide whether a pixel becomes
white (255) or black (0). Values greater than the threshold will be
set to white. Default is 128.</dd>
<dt><strong><code>grayscale</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, the image will be converted to grayscale before binarization.
Default is True.</dd>
<dt><strong><code>color</code></strong> :&ensp;<code>Color</code>, optional</dt>
<dd>A color to replace black pixels in the image when <code>grayscale</code> is False.
If None, the black pixels will remain black. Default is None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>The method modifies the image in place, converting it to binary (black and white).</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; picture = Picture(image)
&gt;&gt;&gt; picture.binarize(threshold=100, grayscale=False, color=RED)
This will binarize the image with a threshold of 100, and replace black pixels with red color.
</code></pre>
<h2 id="notes">Notes</h2>
<ul>
<li>If <code>grayscale</code> is True or <code>color</code> is specified, the image is first converted to grayscale.</li>
<li>The image is processed pixel by pixel, and each pixel value is compared to the threshold.
If the pixel value is above the threshold, it is set to white (255), and if it is below, it is
set to black (0).</li>
<li>If <code>color</code> is specified, black pixels will be replaced with the given color.</li>
</ul></div>
</dd>
<dt id="machina.pixel.picture.Picture.blur"><code class="name flex">
<span>def <span class="ident">blur</span></span>(<span>self, radius: float)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def blur(self, radius: float):
    &#34;&#34;&#34;
    Apply a Gaussian Blur to the Image

    This method applies a Gaussian blur filter to the current image, which softens the image by
    averaging nearby pixels. The intensity of the blur is determined by the radius parameter.
    Larger values for the radius will result in a stronger blur effect.

    Args:
        radius (float): The radius of the blur. A higher radius value results in a more blurred image.

    Returns:
        None
    &#34;&#34;&#34;
    self.image = self.image.filter(ImageFilter.GaussianBlur(radius))</code></pre>
</details>
<div class="desc"><p>Apply a Gaussian Blur to the Image</p>
<p>This method applies a Gaussian blur filter to the current image, which softens the image by
averaging nearby pixels. The intensity of the blur is determined by the radius parameter.
Larger values for the radius will result in a stronger blur effect.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>radius</code></strong> :&ensp;<code>float</code></dt>
<dd>The radius of the blur. A higher radius value results in a more blurred image.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
</dd>
<dt id="machina.pixel.picture.Picture.convert_to_grayscale"><code class="name flex">
<span>def <span class="ident">convert_to_grayscale</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_to_grayscale(self):
    &#34;&#34;&#34;
    Converts the image mode to grayscale (L).
    &#34;&#34;&#34;
    self.image = self.image.convert(&#39;L&#39;)</code></pre>
</details>
<div class="desc"><p>Converts the image mode to grayscale (L).</p></div>
</dd>
<dt id="machina.pixel.picture.Picture.convert_to_rgb"><code class="name flex">
<span>def <span class="ident">convert_to_rgb</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_to_rgb(self):
    &#34;&#34;&#34;
    Convert the image mode to RGB.
    &#34;&#34;&#34;
    self.image = self.image.convert(&#39;RGB&#39;)</code></pre>
</details>
<div class="desc"><p>Convert the image mode to RGB.</p></div>
</dd>
<dt id="machina.pixel.picture.Picture.convert_to_rgba"><code class="name flex">
<span>def <span class="ident">convert_to_rgba</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_to_rgba(self):
    &#34;&#34;&#34;
    Convert the image mode to RGBA
    &#34;&#34;&#34;
    self.image = self.image.convert(&#39;RGBA&#39;)</code></pre>
</details>
<div class="desc"><p>Convert the image mode to RGBA</p></div>
</dd>
<dt id="machina.pixel.picture.Picture.copy"><code class="name flex">
<span>def <span class="ident">copy</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy(self):
    &#34;&#34;&#34;
    Return a copy of the `Picture` instance.
    &#34;&#34;&#34;
    return Picture.from_PIL_image(self.image.copy())</code></pre>
</details>
<div class="desc"><p>Return a copy of the <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> instance.</p></div>
</dd>
<dt id="machina.pixel.picture.Picture.create_alpha_mask"><code class="name flex">
<span>def <span class="ident">create_alpha_mask</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_alpha_mask(self):
    &#34;&#34;&#34;
    Create an Alpha Mask for the Image

    This method generates an alpha mask for the image, where pixels with a value of 0 (black)
    are set to fully transparent (alpha = 0) and non-zero pixels are set to partially transparent
    (alpha = 1). It creates an RGBA image with the alpha channel representing the mask.

    The image is first copied and then processed to create an RGBA version where the alpha channel
    is set based on the binarized pixel values. After creating the mask, the image is converted
    back to grayscale.

    Returns:
        None

    Notes:
        - The method assumes that the image is already in a format that can be binarized.
        - The alpha mask is based on the binary representation of the image.
        - The image is processed pixel by pixel, and an RGBA image is created.
    &#34;&#34;&#34;
    binarized_image = self.copy()
    self.convert_to_rgba()
    for y in range(self.image.height):
        for x in range(self.image.width):
            pixel_value = binarized_image.image.getpixel((x, y))
            if pixel_value == 0:
                self.image.putpixel((x, y), (255, 255, 255, 0))
            else:
                self.image.putpixel((x, y), (0, 0, 0, 1))
    self.convert_to_grayscale()</code></pre>
</details>
<div class="desc"><p>Create an Alpha Mask for the Image</p>
<p>This method generates an alpha mask for the image, where pixels with a value of 0 (black)
are set to fully transparent (alpha = 0) and non-zero pixels are set to partially transparent
(alpha = 1). It creates an RGBA image with the alpha channel representing the mask.</p>
<p>The image is first copied and then processed to create an RGBA version where the alpha channel
is set based on the binarized pixel values. After creating the mask, the image is converted
back to grayscale.</p>
<h2 id="returns">Returns</h2>
<p>None</p>
<h2 id="notes">Notes</h2>
<ul>
<li>The method assumes that the image is already in a format that can be binarized.</li>
<li>The alpha mask is based on the binary representation of the image.</li>
<li>The image is processed pixel by pixel, and an RGBA image is created.</li>
</ul></div>
</dd>
<dt id="machina.pixel.picture.Picture.crop"><code class="name flex">
<span>def <span class="ident">crop</span></span>(<span>self, left_margin, top_margin, right_margin, bottom_margin)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crop(self, left_margin, top_margin, right_margin, bottom_margin):
    &#34;&#34;&#34;
    Crops the image by removing the specified margins from the left, top, right, and bottom edges.

    Args:
        left_margin (int): The number of pixels to remove from the left edge of the image.
        top_margin (int): The number of pixels to remove from the top edge of the image.
        right_margin (int): The number of pixels to remove from the right edge of the image.
        bottom_margin (int): The number of pixels to remove from the bottom edge of the image.

    Example:
        &gt;&gt;&gt; picture = Picture(image)
        &gt;&gt;&gt; picture.crop(50, 30, 50, 30)
        This will crop the image by removing 50 pixels from the left, 30 from the top, 50 from the right,
        and 30 from the bottom.
    &#34;&#34;&#34;
    width, height = self.size
    self.image = self.image.crop((left_margin, top_margin, width - right_margin, height - bottom_margin))</code></pre>
</details>
<div class="desc"><p>Crops the image by removing the specified margins from the left, top, right, and bottom edges.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>left_margin</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of pixels to remove from the left edge of the image.</dd>
<dt><strong><code>top_margin</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of pixels to remove from the top edge of the image.</dd>
<dt><strong><code>right_margin</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of pixels to remove from the right edge of the image.</dd>
<dt><strong><code>bottom_margin</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of pixels to remove from the bottom edge of the image.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; picture = Picture(image)
&gt;&gt;&gt; picture.crop(50, 30, 50, 30)
This will crop the image by removing 50 pixels from the left, 30 from the top, 50 from the right,
and 30 from the bottom.
</code></pre></div>
</dd>
<dt id="machina.pixel.picture.Picture.dither_floyd_steinberg"><code class="name flex">
<span>def <span class="ident">dither_floyd_steinberg</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dither_floyd_steinberg(self, **kwargs):
    &#34;&#34;&#34;
    Apply Floyd-Steinberg Dithering to the Image

    This method applies the Floyd-Steinberg dithering algorithm, a popular error-diffusion technique
    used to convert grayscale images into a binary representation while preserving the appearance of
    continuous tones. The method scales the image, applies the dithering, and then resizes it back to
    the original size.

    Args:
        scale_factor (int, optional): The scaling factor for the image before applying the dithering.
                                    A larger value reduces the amount of scaling applied to the image.
                                    Defaults to 3.

    Returns:
        None

    Example:
        &gt;&gt;&gt; picture = Picture(image)
        &gt;&gt;&gt; picture.dither_floyd_steinberg(scale_factor=4)
        This will apply Floyd-Steinberg dithering to the image with a scale factor of 4.

    Notes:
        - The image is first converted to grayscale before applying the dithering.
        - The algorithm works by diffusing the error between the pixel value and the nearest threshold
        (either 0 or 255) to neighboring pixels.
        - The image is scaled down by the specified `scale_factor` to speed up the dithering process,
        and then scaled back to the original dimensions after dithering.
        - The error diffusion weights for the Floyd-Steinberg algorithm are as follows:
        - (7/16) to the pixel to the right
        - (3/16) to the pixel below-left
        - (5/16) to the pixel below
        - (1/16) to the pixel below-right
    &#34;&#34;&#34;

    scale_factor = kwargs.get(&#39;scale_factor&#39;, 3)

    self.convert_to_grayscale()
    pixels = np.array(self.image, dtype=np.float32)
    height, width = pixels.shape

    scaled_height = int(height / scale_factor)
    scaled_width = int(width / scale_factor)
    scaled_image = Image.fromarray(pixels.astype(np.uint8)).resize((scaled_width, scaled_height), Image.Resampling.NEAREST)
    pixels = np.array(scaled_image, dtype=np.float32)

    for y in range(scaled_height):
        for x in range(scaled_width):
            old_pixel = pixels[y, x]
            new_pixel = 255 if old_pixel &gt; 127 else 0
            pixels[y, x] = new_pixel
            quant_error = old_pixel - new_pixel

            if x &lt; scaled_width - 1:
                pixels[y, x + 1] += quant_error * (7 / 16)
            if y &lt; scaled_height - 1:
                if x &gt; 0:
                    pixels[y + 1, x - 1] += quant_error * (3 / 16)
                pixels[y + 1, x] += quant_error * (5 / 16)
                if x &lt; scaled_width - 1:
                    pixels[y + 1, x + 1] += quant_error * (1 / 16)

    dithered_image = Image.fromarray(np.clip(pixels, 0, 255).astype(np.uint8), mode=&#39;L&#39;)
    dithered_image = dithered_image.resize((width, height), Image.Resampling.NEAREST)
    self.image = dithered_image</code></pre>
</details>
<div class="desc"><p>Apply Floyd-Steinberg Dithering to the Image</p>
<p>This method applies the Floyd-Steinberg dithering algorithm, a popular error-diffusion technique
used to convert grayscale images into a binary representation while preserving the appearance of
continuous tones. The method scales the image, applies the dithering, and then resizes it back to
the original size.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>scale_factor</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The scaling factor for the image before applying the dithering.
A larger value reduces the amount of scaling applied to the image.
Defaults to 3.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; picture = Picture(image)
&gt;&gt;&gt; picture.dither_floyd_steinberg(scale_factor=4)
This will apply Floyd-Steinberg dithering to the image with a scale factor of 4.
</code></pre>
<h2 id="notes">Notes</h2>
<ul>
<li>The image is first converted to grayscale before applying the dithering.</li>
<li>The algorithm works by diffusing the error between the pixel value and the nearest threshold
(either 0 or 255) to neighboring pixels.</li>
<li>The image is scaled down by the specified <code>scale_factor</code> to speed up the dithering process,
and then scaled back to the original dimensions after dithering.</li>
<li>The error diffusion weights for the Floyd-Steinberg algorithm are as follows:</li>
<li>(7/16) to the pixel to the right</li>
<li>(3/16) to the pixel below-left</li>
<li>(5/16) to the pixel below</li>
<li>(1/16) to the pixel below-right</li>
</ul></div>
</dd>
<dt id="machina.pixel.picture.Picture.dither_halftone"><code class="name flex">
<span>def <span class="ident">dither_halftone</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dither_halftone(self, **kwargs):
    &#34;&#34;&#34;
    Apply a Halftone Dither Effect to the Image

    This method converts the image to grayscale and applies a halftone dithering effect,
    where the brightness of the image is represented using dots of varying sizes. The dots
    are placed in a grid pattern, with darker areas having larger dots and lighter areas
    having smaller dots.

    Args:
        dot_color (Color, optional): The color of the halftone dots. Defaults to black.
        background_color (Color, optional): The background color for the image. Defaults to white.
        dot_spacing (int, optional): The spacing between the dots in the grid. Defaults to 12 pixels.
        dot_size (int, optional): The maximum size of the dots. Defaults to 8 pixels.

    Returns:
        None

    Example:
        &gt;&gt;&gt; picture = Picture(image)
        &gt;&gt;&gt; picture.dither_halftone(dot_color=RED, background_color=WHITE, dot_spacing=10, dot_size=5)
        This will apply a halftone dithering effect with red dots, a white background, and customized spacing and dot size.

    Notes:
        - The image is first converted to grayscale before applying the halftone effect.
        - The brightness of each pixel determines the size of the dots, with darker areas having larger dots.
        - The method uses a grid pattern with adjustable dot spacing and size to create the halftone effect.

    &#34;&#34;&#34;
    # Kwargs
    dot_color = kwargs.get(&#39;dot_color&#39;, Color.BLACK)
    background_color = kwargs.get(&#39;background_color&#39;, Color.WHITE)
    dot_spacing = kwargs.get(&#39;dot_spacing&#39;, 12)
    dot_size = kwargs.get(&#39;dot_size&#39;, 8)

    # Open image and convert to grayscale
    self.convert_to_grayscale()
    width, height = self.size
    halftone = Image.new(&#39;RGB&#39;, (width, height), background_color.rgb)
    draw = ImageDraw.Draw(halftone)

    # Process image in a grid pattern
    for y in range(0, height, dot_spacing):
        for x in range(0, width, dot_spacing):
            # Get pixel brightness (0-255, where 0 is black and 255 is white)
            pixel_value = self.image.getpixel((x, y))

            # Handle different pixel formats
            if isinstance(pixel_value, int):  # Grayscale
                brightness = float(pixel_value)
            elif isinstance(pixel_value, tuple) and len(pixel_value) &gt; 0:
                brightness = float(pixel_value[0])  # Take first channel
            else:
                brightness = 0.0  # Default if pixel format is unexpected

            # Scale dot size based on brightness (darker areas have larger dots)
            radius = (1 - brightness / 255) * dot_size / 2

            if radius &gt; 0:
                draw.ellipse((x - radius, y - radius, x + radius, y + radius), fill=dot_color.rgb)

    self.image = halftone</code></pre>
</details>
<div class="desc"><p>Apply a Halftone Dither Effect to the Image</p>
<p>This method converts the image to grayscale and applies a halftone dithering effect,
where the brightness of the image is represented using dots of varying sizes. The dots
are placed in a grid pattern, with darker areas having larger dots and lighter areas
having smaller dots.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dot_color</code></strong> :&ensp;<code>Color</code>, optional</dt>
<dd>The color of the halftone dots. Defaults to black.</dd>
<dt><strong><code>background_color</code></strong> :&ensp;<code>Color</code>, optional</dt>
<dd>The background color for the image. Defaults to white.</dd>
<dt><strong><code>dot_spacing</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The spacing between the dots in the grid. Defaults to 12 pixels.</dd>
<dt><strong><code>dot_size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The maximum size of the dots. Defaults to 8 pixels.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; picture = Picture(image)
&gt;&gt;&gt; picture.dither_halftone(dot_color=RED, background_color=WHITE, dot_spacing=10, dot_size=5)
This will apply a halftone dithering effect with red dots, a white background, and customized spacing and dot size.
</code></pre>
<h2 id="notes">Notes</h2>
<ul>
<li>The image is first converted to grayscale before applying the halftone effect.</li>
<li>The brightness of each pixel determines the size of the dots, with darker areas having larger dots.</li>
<li>The method uses a grid pattern with adjustable dot spacing and size to create the halftone effect.</li>
</ul></div>
</dd>
<dt id="machina.pixel.picture.Picture.dither_ordered"><code class="name flex">
<span>def <span class="ident">dither_ordered</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dither_ordered(self, **kwargs):
    &#34;&#34;&#34;
    Apply Ordered Dithering to the Image using Bayer Matrix

    This method applies ordered dithering to an image using a Bayer matrix, which is a technique
    to convert grayscale images to a binary representation using a threshold map. The method
    divides the image into a grid pattern and uses a Bayer matrix of a specified size to
    determine the threshold for dithering.

    Args:
        matrix_size (int, optional): The size of the Bayer matrix to use for dithering.
                                    Supported values are 2, 4, or 8. Defaults to 8.
        scale_factor (int, optional): The size of the grid to process in the dithering.
                                    Defaults to 5 pixels.
        color (Color, optional): The color for the &#34;on&#34; pixels in the dithering (typically white).
                                Defaults to white.
        background_color (Color, optional): The color for the &#34;off&#34; pixels in the dithering (typically black).
                                            Defaults to black.

    Returns:
        None

    Example:
        &gt;&gt;&gt; picture = Picture(image)
        &gt;&gt;&gt; picture.dither_ordered(matrix_size=4, scale_factor=6, color=WHITE, background_color=BLACK)
        This will apply ordered dithering to the image using a 4x4 Bayer matrix,
        with a scale factor of 6 pixels for each grid and white for the &#34;on&#34; color.

    Notes:
        - The Bayer matrices of size 2, 4, and 8 are pre-defined, and the dithering is based on the threshold values
        derived from these matrices.
        - The method processes the image in blocks of the specified `scale_factor` and applies the dithering based on
        pixel brightness in relation to the corresponding threshold in the Bayer matrix.
    &#34;&#34;&#34;
    # Kwargs
    matrix_size = kwargs.get(&#39;matrix_size&#39;, 8)
    scale_factor = kwargs.get(&#39;scale_factor&#39;, 5)
    color = kwargs.get(&#39;color&#39;, Color.WHITE)
    background_color = kwargs.get(&#39;background_color&#39;, Color.BLACK)

    # Bayer matrices of different sizes
    bayer_matrices = {
        2: np.array([[0, 2], [3, 1]]) / 4.0,
        4: np.array([[0, 8, 2, 10], [12, 4, 14, 6], [3, 11, 1, 9], [15, 7, 13, 5]]) / 16.0,
        8: np.array([
            [0, 32, 8, 40, 2, 34, 10, 42],
            [48, 16, 56, 24, 50, 18, 58, 26],
            [12, 44, 4, 36, 14, 46, 6, 38],
            [60, 28, 52, 20, 62, 30, 54, 22],
            [3, 35, 11, 43, 1, 33, 9, 41],
            [51, 19, 59, 27, 49, 17, 57, 25],
            [15, 47, 7, 39, 13, 45, 5, 37],
            [63, 31, 55, 23, 61, 29, 53, 21]
        ]) / 64.0
    }

    if matrix_size not in bayer_matrices:
        raise ValueError(&#34;Unsupported matrix size. Choose from 2, 4, or 8.&#34;)

    bayer_matrix = bayer_matrices[matrix_size]
    threshold_map = (bayer_matrix * 255).astype(np.uint8)

    # Open image and convert to grayscale
    self.convert_to_grayscale()
    width, height = self.image.size
    pixels = np.array(self.image, dtype=np.uint8)

    # Convert image to RGB to sore colore pixels
    color_pixels = np.zeros((height, width, 3), dtype=np.uint8)

    # Apply dithering
    for y in range(0, height, scale_factor):
        for x in range(0, width, scale_factor):
            threshold = threshold_map[(y // scale_factor) % matrix_size, (x // scale_factor) % matrix_size]
            color_pixels[y:y+scale_factor, x:x+scale_factor] = color.rgb if pixels[y, x] &gt; threshold else background_color.rgb

    dithered_image = Image.fromarray(color_pixels, mode=&#39;RGB&#39;)
    self.image =  dithered_image</code></pre>
</details>
<div class="desc"><p>Apply Ordered Dithering to the Image using Bayer Matrix</p>
<p>This method applies ordered dithering to an image using a Bayer matrix, which is a technique
to convert grayscale images to a binary representation using a threshold map. The method
divides the image into a grid pattern and uses a Bayer matrix of a specified size to
determine the threshold for dithering.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>matrix_size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The size of the Bayer matrix to use for dithering.
Supported values are 2, 4, or 8. Defaults to 8.</dd>
<dt><strong><code>scale_factor</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The size of the grid to process in the dithering.
Defaults to 5 pixels.</dd>
<dt><strong><code>color</code></strong> :&ensp;<code>Color</code>, optional</dt>
<dd>The color for the "on" pixels in the dithering (typically white).
Defaults to white.</dd>
<dt><strong><code>background_color</code></strong> :&ensp;<code>Color</code>, optional</dt>
<dd>The color for the "off" pixels in the dithering (typically black).
Defaults to black.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; picture = Picture(image)
&gt;&gt;&gt; picture.dither_ordered(matrix_size=4, scale_factor=6, color=WHITE, background_color=BLACK)
This will apply ordered dithering to the image using a 4x4 Bayer matrix,
with a scale factor of 6 pixels for each grid and white for the &quot;on&quot; color.
</code></pre>
<h2 id="notes">Notes</h2>
<ul>
<li>The Bayer matrices of size 2, 4, and 8 are pre-defined, and the dithering is based on the threshold values
derived from these matrices.</li>
<li>The method processes the image in blocks of the specified <code>scale_factor</code> and applies the dithering based on
pixel brightness in relation to the corresponding threshold in the Bayer matrix.</li>
</ul></div>
</dd>
<dt id="machina.pixel.picture.Picture.draw_arrow"><code class="name flex">
<span>def <span class="ident">draw_arrow</span></span>(<span>self,<br>start: tuple,<br>end: tuple,<br>width=3,<br>arrowhead_length=50,<br>arrowhead_angle=30,<br>**kwargs) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def draw_arrow(self, start: tuple, end: tuple, width=3, arrowhead_length=50, arrowhead_angle=30, **kwargs) -&gt; None:
    color = kwargs.get(&#39;color&#39;, Color.WHITE)

    draw = ImageDraw.Draw(self.image)

    # Draw the main shaft
    draw.line([start, end], fill=color.rgb, width=width)

    # Direction vector
    dx = end[0] - start[0]
    dy = end[1] - start[1]
    angle = math.atan2(dy, dx)

    # Arrowhead points
    left_angle = angle + math.radians(arrowhead_angle)
    right_angle = angle - math.radians(arrowhead_angle)

    left_point = (
        end[0] - arrowhead_length * math.cos(left_angle),
        end[1] - arrowhead_length * math.sin(left_angle)
    )
    right_point = (
        end[0] - arrowhead_length * math.cos(right_angle),
        end[1] - arrowhead_length * math.sin(right_angle)
    )

    # Draw filled triangle for arrowhead
    draw.polygon([end, left_point, right_point], fill=color.rgb)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="machina.pixel.picture.Picture.draw_circle"><code class="name flex">
<span>def <span class="ident">draw_circle</span></span>(<span>self, center: tuple[int, int], radius: int, **kwargs) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def draw_circle(self, center: tuple[int, int], radius: int, **kwargs) -&gt; None:
    &#34;&#34;&#34;
    Draw a circle on the image with the given center and radius.
    
    Args:
        center (tuple): The center point of the circle (x, y).
        radius (int): The radius of the circle.
        **kwargs: Optional keyword arguments for customization.
                - &#39;color&#39;: The color of the circle. Defaults to `WHITE`.
    
    Returns:
        None
    &#34;&#34;&#34;
    color: Color = kwargs.get(&#39;color&#39;, Color.WHITE)

    draw = ImageDraw.Draw(self.image)
    x, y = center
    bounding_box = [x - radius, y - radius, x + radius, y + radius]
    draw.ellipse(bounding_box, width=5, fill=color.rgb)</code></pre>
</details>
<div class="desc"><p>Draw a circle on the image with the given center and radius.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>center</code></strong> :&ensp;<code>tuple</code></dt>
<dd>The center point of the circle (x, y).</dd>
<dt><strong><code>radius</code></strong> :&ensp;<code>int</code></dt>
<dd>The radius of the circle.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Optional keyword arguments for customization.
- 'color': The color of the circle. Defaults to <code>WHITE</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
</dd>
<dt id="machina.pixel.picture.Picture.draw_line"><code class="name flex">
<span>def <span class="ident">draw_line</span></span>(<span>self, start: tuple, end: tuple, **kwargs) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def draw_line(self, start: tuple, end: tuple, **kwargs) -&gt; None:
    &#34;&#34;&#34;
    Draw a line between two points on the image.
    
    Args:
        start (tuple): The starting point of the line (x1, y1).
        end (tuple): The ending point of the line (x2, y2).
        width (int, optional): The width of the line. Defaults to 3.
        **kwargs: Optional keyword arguments for customization. 
                - &#39;color&#39; (Color): The color of the line. Defaults to `WHITE`.
                - &#39;width&#39; (int): The width of the line. Defaults to 3.
    
    Returns:
        None
    &#34;&#34;&#34;
    color = kwargs.get(&#39;color&#39;, Color.WHITE)
    width = kwargs.get(&#39;width&#39;, 3)

    draw = ImageDraw.Draw(self.image)
    draw.line([start, end], fill=color.rgb, width=width)</code></pre>
</details>
<div class="desc"><p>Draw a line between two points on the image.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start</code></strong> :&ensp;<code>tuple</code></dt>
<dd>The starting point of the line (x1, y1).</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>tuple</code></dt>
<dd>The ending point of the line (x2, y2).</dd>
<dt><strong><code>width</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The width of the line. Defaults to 3.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Optional keyword arguments for customization.
- 'color' (Color): The color of the line. Defaults to <code>WHITE</code>.
- 'width' (int): The width of the line. Defaults to 3.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
</dd>
<dt id="machina.pixel.picture.Picture.draw_text"><code class="name flex">
<span>def <span class="ident">draw_text</span></span>(<span>self, text: str, position: tuple[int, int], font_size, **kwargs) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def draw_text(self, text: str, position: tuple[int, int], font_size, **kwargs) -&gt; None:
    &#34;&#34;&#34;
    Draw text on the image at the specified position with the given font size.
    
    Args:
        text (str): The text to be drawn.
        position (tuple): The (x, y) position where the text&#39;s baseline will be.
        font_size (int): The font size.
        **kwargs: Optional keyword arguments for customization.
                - &#39;color&#39;: The color of the text. Defaults to `Color.BLACK`.
    
    Returns:
        None
    &#34;&#34;&#34;
    color = kwargs.get(&#39;color&#39;,Color.BLACK)

    draw = ImageDraw.Draw(self.image)
    font_path = os.path.join(os.path.dirname(__file__), &#39;..&#39;, &#39;fonts&#39;, &#39;font_test.ttf&#39;)
    font = ImageFont.truetype(font_path, font_size)

    # Measure text size
    bbox = draw.textbbox((0, 0), text, font=font)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]

    # Adjust position if centering
    x, y = position
    x -= text_width // 2
    y -= text_height // 2

    draw.text((x, y), text, fill=color.rgb, font=font)</code></pre>
</details>
<div class="desc"><p>Draw text on the image at the specified position with the given font size.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>text</code></strong> :&ensp;<code>str</code></dt>
<dd>The text to be drawn.</dd>
<dt><strong><code>position</code></strong> :&ensp;<code>tuple</code></dt>
<dd>The (x, y) position where the text's baseline will be.</dd>
<dt><strong><code>font_size</code></strong> :&ensp;<code>int</code></dt>
<dd>The font size.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Optional keyword arguments for customization.
- 'color': The color of the text. Defaults to <code>Color.BLACK</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
</dd>
<dt id="machina.pixel.picture.Picture.flip_horizontal"><code class="name flex">
<span>def <span class="ident">flip_horizontal</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def flip_horizontal(self):
    &#34;&#34;&#34;
    Flips the image horizontally.
    &#34;&#34;&#34;
    self.image = ImageOps.mirror(self.image)</code></pre>
</details>
<div class="desc"><p>Flips the image horizontally.</p></div>
</dd>
<dt id="machina.pixel.picture.Picture.flip_vertical"><code class="name flex">
<span>def <span class="ident">flip_vertical</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def flip_vertical(self):
    &#34;&#34;&#34;
    Flips the image vertically.
    &#34;&#34;&#34;
    self.image = ImageOps.flip(self.image)</code></pre>
</details>
<div class="desc"><p>Flips the image vertically.</p></div>
</dd>
<dt id="machina.pixel.picture.Picture.get_color_palette"><code class="name flex">
<span>def <span class="ident">get_color_palette</span></span>(<span>self, num_colors)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_color_palette(self, num_colors):
    &#34;&#34;&#34;
    Return a `Picture` of the colorpalette of the image.

    Args:
        num_colors (int): number of colors to include in the color palette.

    Returns:
        Picture: color palette of the picture.
    &#34;&#34;&#34;
    colors = self.get_main_colors(num_colors)
    color_pictures = []
    for color in colors:
        color_pictures.append(Picture.from_PIL_image(Image.new(&#39;RGB&#39;, (100, 100), color.rgb)))
    palette = create_grid_of_pictures(color_pictures, grid_size=(num_colors, 1), image_size=(100, 100))
    return palette</code></pre>
</details>
<div class="desc"><p>Return a <code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code> of the colorpalette of the image.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>num_colors</code></strong> :&ensp;<code>int</code></dt>
<dd>number of colors to include in the color palette.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd>color palette of the picture.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.get_main_colors"><code class="name flex">
<span>def <span class="ident">get_main_colors</span></span>(<span>self, num_colors) ‑> list[<a title="machina.artist.color.Color" href="../artist/color.html#machina.artist.color.Color">Color</a>]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_main_colors(self, num_colors) -&gt; list[Color]:
    &#34;&#34;&#34;
    Return a list of the main $n$ colors of the image.

    Args:
        num_colors (int): number of main colors to return

    Returns:
        list[Color]: list of HAL.pixels.Color objects.
    &#34;&#34;&#34;
    # Convert image to &#34;P&#34; mode (palette-based) with an adaptive palette
    image = self.image.convert(&#34;P&#34;, palette=Image.Palette.ADAPTIVE, colors=num_colors)

    # Get the palette (a list of RGB values, where every 3 values are an (R, G, B) triplet)
    palette = image.getpalette()
    if palette is None:
        return []

    palette = palette[:num_colors * 3]  # Only get requested number of colors

    # Convert flat list to list of RGB tuples
    colors = [tuple(palette[i:i+3]) for i in range(0, len(palette), 3)]
    colors = [Color(c[0], c[1], c[2]) for c in colors]
    return colors</code></pre>
</details>
<div class="desc"><p>Return a list of the main $n$ colors of the image.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>num_colors</code></strong> :&ensp;<code>int</code></dt>
<dd>number of main colors to return</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list[Color]</code></dt>
<dd>list of HAL.pixels.Color objects.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.get_pixel_color"><code class="name flex">
<span>def <span class="ident">get_pixel_color</span></span>(<span>self, coord_x: int, coord_y: int) ‑> <a title="machina.artist.color.Color" href="../artist/color.html#machina.artist.color.Color">Color</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_pixel_color(self, coord_x: int, coord_y: int) -&gt; Color:
    &#34;&#34;&#34;
    Get the color of a pixel at the specified coordinates (coord_x, coord_y).
    
    Args:
        coord_x (int): The x-coordinate of the pixel.
        coord_y (int): The y-coordinate of the pixel.
    
    Returns:
        Color: The color of the pixel as a Color object.
    
    Raises:
        ValueError: If the pixel format is unexpected.
    &#34;&#34;&#34;
    pixel_value = self.image.getpixel((coord_x, coord_y))

    if isinstance(pixel_value, int):  # Grayscale
        return Color(pixel_value, pixel_value, pixel_value)
    elif isinstance(pixel_value, tuple):
        if len(pixel_value) &gt;= 3:
            return Color(pixel_value[0], pixel_value[1], pixel_value[2])
        # Handle other tuple lengths if needed

    # Fallback or raise an error
    raise ValueError(f&#34;Unexpected pixel format: {pixel_value}&#34;)</code></pre>
</details>
<div class="desc"><p>Get the color of a pixel at the specified coordinates (coord_x, coord_y).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>coord_x</code></strong> :&ensp;<code>int</code></dt>
<dd>The x-coordinate of the pixel.</dd>
<dt><strong><code>coord_y</code></strong> :&ensp;<code>int</code></dt>
<dd>The y-coordinate of the pixel.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Color</code></dt>
<dd>The color of the pixel as a Color object.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the pixel format is unexpected.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.invert_colors"><code class="name flex">
<span>def <span class="ident">invert_colors</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def invert_colors(self):
    &#34;&#34;&#34;
    Invert the Colors of the Image

    This method inverts the colors of the current image, transforming all pixels in the image
    to their complementary color. Each pixel&#39;s red, green, and blue values are inverted, meaning
    that the color channels are flipped to their opposite values. For example, a white pixel (255, 255, 255)
    would become black (0, 0, 0), and vice versa.

    Args:
        None: This method operates directly on the current image.

    Returns:
        None
    &#34;&#34;&#34;
    self.image = ImageOps.invert(self.image)</code></pre>
</details>
<div class="desc"><p>Invert the Colors of the Image</p>
<p>This method inverts the colors of the current image, transforming all pixels in the image
to their complementary color. Each pixel's red, green, and blue values are inverted, meaning
that the color channels are flipped to their opposite values. For example, a white pixel (255, 255, 255)
would become black (0, 0, 0), and vice versa.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>None</code></strong></dt>
<dd>This method operates directly on the current image.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
</dd>
<dt id="machina.pixel.picture.Picture.paste_picture"><code class="name flex">
<span>def <span class="ident">paste_picture</span></span>(<span>self, picture_to_paste, coord_x: int, coord_y: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def paste_picture(self, picture_to_paste, coord_x: int, coord_y: int):
    &#34;&#34;&#34;
    Paste one picture onto another at the specified coordinates while handling transparency.
    
    Args:
        picture_to_paste (Picture): The picture to be pasted.
        coord_x (int): The x-coordinate where the picture should be pasted.
        coord_y (int): The y-coordinate where the picture should be pasted.
    &#34;&#34;&#34;
    mask = picture_to_paste.copy()
    mask.convert_to_rgba()
    self.image.paste(picture_to_paste.image, (coord_x, coord_y), mask.image)</code></pre>
</details>
<div class="desc"><p>Paste one picture onto another at the specified coordinates while handling transparency.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>picture_to_paste</code></strong> :&ensp;<code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></dt>
<dd>The picture to be pasted.</dd>
<dt><strong><code>coord_x</code></strong> :&ensp;<code>int</code></dt>
<dd>The x-coordinate where the picture should be pasted.</dd>
<dt><strong><code>coord_y</code></strong> :&ensp;<code>int</code></dt>
<dd>The y-coordinate where the picture should be pasted.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.resize"><code class="name flex">
<span>def <span class="ident">resize</span></span>(<span>self, width, height, keep_aspect_ratio=True, crop=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resize(self, width, height, keep_aspect_ratio = True, crop = False):
    &#34;&#34;&#34;
    Resizes the image according to the specified width and height, with options to maintain
    the aspect ratio and/or crop the image. Different resizing methods are used depending on the combination
    of options chosen.

    Args:
        width (int): The target width of the resized image.
        height (int): The target height of the resized image.
        keep_aspect_ratio (bool, optional): Whether to preserve the original aspect ratio of the image.
                                            Defaults to True. If True, the image is resized to fit within the
                                            specified dimensions.
                                            If False, the image is resized to exactly match the target dimensions.
        crop (bool, optional): Whether to crop the image to fit the specified dimensions. Defaults to False.
                            If True, the image will be cropped to maintain the aspect ratio after resizing
                            (used when `keep_aspect_ratio` is also True).
    &#34;&#34;&#34;
    if keep_aspect_ratio and not crop:
        self.image = ImageOps.cover(self.image, (width, height))
    if (keep_aspect_ratio and crop) or crop:
        self.image = ImageOps.fit(self.image, (width, height))
    if not keep_aspect_ratio and not crop:
        self.image = self.image.resize((width, height))</code></pre>
</details>
<div class="desc"><p>Resizes the image according to the specified width and height, with options to maintain
the aspect ratio and/or crop the image. Different resizing methods are used depending on the combination
of options chosen.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>width</code></strong> :&ensp;<code>int</code></dt>
<dd>The target width of the resized image.</dd>
<dt><strong><code>height</code></strong> :&ensp;<code>int</code></dt>
<dd>The target height of the resized image.</dd>
<dt><strong><code>keep_aspect_ratio</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to preserve the original aspect ratio of the image.
Defaults to True. If True, the image is resized to fit within the
specified dimensions.
If False, the image is resized to exactly match the target dimensions.</dd>
<dt><strong><code>crop</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to crop the image to fit the specified dimensions. Defaults to False.
If True, the image will be cropped to maintain the aspect ratio after resizing
(used when <code>keep_aspect_ratio</code> is also True).</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.rotate"><code class="name flex">
<span>def <span class="ident">rotate</span></span>(<span>self, angle)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotate(self, angle):
    &#34;&#34;&#34;
    Rotates the image by the `angle` expressed in degrees.

    Args:
        angle (float): angle of rotation in degrees
    &#34;&#34;&#34;
    self.image = self.image.rotate(angle)</code></pre>
</details>
<div class="desc"><p>Rotates the image by the <code>angle</code> expressed in degrees.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>angle</code></strong> :&ensp;<code>float</code></dt>
<dd>angle of rotation in degrees</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, output_path)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, output_path):
    &#34;&#34;&#34;
    Saves the image to a file.

    Args:
        output_path (str): The pathe on which to save the image.
    &#34;&#34;&#34;
    self.image.save(output_path)</code></pre>
</details>
<div class="desc"><p>Saves the image to a file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>output_path</code></strong> :&ensp;<code>str</code></dt>
<dd>The pathe on which to save the image.</dd>
</dl></div>
</dd>
<dt id="machina.pixel.picture.Picture.show"><code class="name flex">
<span>def <span class="ident">show</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show(self):
    &#34;&#34;&#34;
    Displays the image using the default image viewer.
    &#34;&#34;&#34;
    self.image.show()</code></pre>
</details>
<div class="desc"><p>Displays the image using the default image viewer.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="machina.pixel" href="index.html">machina.pixel</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="machina.pixel.picture.add_centered_text" href="#machina.pixel.picture.add_centered_text">add_centered_text</a></code></li>
<li><code><a title="machina.pixel.picture.blend_images" href="#machina.pixel.picture.blend_images">blend_images</a></code></li>
<li><code><a title="machina.pixel.picture.create_grid_of_pictures" href="#machina.pixel.picture.create_grid_of_pictures">create_grid_of_pictures</a></code></li>
<li><code><a title="machina.pixel.picture.get_blank_picture" href="#machina.pixel.picture.get_blank_picture">get_blank_picture</a></code></li>
<li><code><a title="machina.pixel.picture.screen_blend" href="#machina.pixel.picture.screen_blend">screen_blend</a></code></li>
<li><code><a title="machina.pixel.picture.superimpose_pictures" href="#machina.pixel.picture.superimpose_pictures">superimpose_pictures</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="machina.pixel.picture.Picture" href="#machina.pixel.picture.Picture">Picture</a></code></h4>
<ul class="">
<li><code><a title="machina.pixel.picture.Picture.adjust_brightness" href="#machina.pixel.picture.Picture.adjust_brightness">adjust_brightness</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.adjust_contrast" href="#machina.pixel.picture.Picture.adjust_contrast">adjust_contrast</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.adjust_saturation" href="#machina.pixel.picture.Picture.adjust_saturation">adjust_saturation</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.adjust_sharpness" href="#machina.pixel.picture.Picture.adjust_sharpness">adjust_sharpness</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.apply_alpha_mask" href="#machina.pixel.picture.Picture.apply_alpha_mask">apply_alpha_mask</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.apply_color_filter" href="#machina.pixel.picture.Picture.apply_color_filter">apply_color_filter</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.binarize" href="#machina.pixel.picture.Picture.binarize">binarize</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.blue_channel" href="#machina.pixel.picture.Picture.blue_channel">blue_channel</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.blur" href="#machina.pixel.picture.Picture.blur">blur</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.convert_to_grayscale" href="#machina.pixel.picture.Picture.convert_to_grayscale">convert_to_grayscale</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.convert_to_rgb" href="#machina.pixel.picture.Picture.convert_to_rgb">convert_to_rgb</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.convert_to_rgba" href="#machina.pixel.picture.Picture.convert_to_rgba">convert_to_rgba</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.copy" href="#machina.pixel.picture.Picture.copy">copy</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.create_alpha_mask" href="#machina.pixel.picture.Picture.create_alpha_mask">create_alpha_mask</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.crop" href="#machina.pixel.picture.Picture.crop">crop</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.dither_floyd_steinberg" href="#machina.pixel.picture.Picture.dither_floyd_steinberg">dither_floyd_steinberg</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.dither_halftone" href="#machina.pixel.picture.Picture.dither_halftone">dither_halftone</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.dither_ordered" href="#machina.pixel.picture.Picture.dither_ordered">dither_ordered</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.draw_arrow" href="#machina.pixel.picture.Picture.draw_arrow">draw_arrow</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.draw_circle" href="#machina.pixel.picture.Picture.draw_circle">draw_circle</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.draw_line" href="#machina.pixel.picture.Picture.draw_line">draw_line</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.draw_text" href="#machina.pixel.picture.Picture.draw_text">draw_text</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.entropy" href="#machina.pixel.picture.Picture.entropy">entropy</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.flip_horizontal" href="#machina.pixel.picture.Picture.flip_horizontal">flip_horizontal</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.flip_vertical" href="#machina.pixel.picture.Picture.flip_vertical">flip_vertical</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.from_PIL_image" href="#machina.pixel.picture.Picture.from_PIL_image">from_PIL_image</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.from_array" href="#machina.pixel.picture.Picture.from_array">from_array</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.from_file_path" href="#machina.pixel.picture.Picture.from_file_path">from_file_path</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.get_color_palette" href="#machina.pixel.picture.Picture.get_color_palette">get_color_palette</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.get_main_colors" href="#machina.pixel.picture.Picture.get_main_colors">get_main_colors</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.get_pixel_color" href="#machina.pixel.picture.Picture.get_pixel_color">get_pixel_color</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.green_channel" href="#machina.pixel.picture.Picture.green_channel">green_channel</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.height" href="#machina.pixel.picture.Picture.height">height</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.invert_colors" href="#machina.pixel.picture.Picture.invert_colors">invert_colors</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.mode" href="#machina.pixel.picture.Picture.mode">mode</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.np_array" href="#machina.pixel.picture.Picture.np_array">np_array</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.paste_picture" href="#machina.pixel.picture.Picture.paste_picture">paste_picture</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.red_channel" href="#machina.pixel.picture.Picture.red_channel">red_channel</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.resize" href="#machina.pixel.picture.Picture.resize">resize</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.rotate" href="#machina.pixel.picture.Picture.rotate">rotate</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.save" href="#machina.pixel.picture.Picture.save">save</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.show" href="#machina.pixel.picture.Picture.show">show</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.size" href="#machina.pixel.picture.Picture.size">size</a></code></li>
<li><code><a title="machina.pixel.picture.Picture.width" href="#machina.pixel.picture.Picture.width">width</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
